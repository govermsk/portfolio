{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import platform\n",
    "import psycopg2\n",
    "import random\n",
    "import re\n",
    "import requests \n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import scipy.sparse as sp\n",
    "import spacy\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from datetime import datetime \n",
    "from datetime import timedelta\n",
    "from lightgbm import LGBMClassifier\n",
    "from random import randint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from scipy.sparse import hstack, vstack\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from numpy import loadtxt\n",
    "from numpy import savetxt\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\serg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\serg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q ipywidgets plotly pyenchant tqdm optuna pandarallel requests swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import enchant\n",
    "import swifter\n",
    "import optuna\n",
    "from pandarallel import pandarallel \n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = enchant.Dict('en_US') # словарь pyenchant для проверки текстов, являются ли они словами\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from tqdm import tqdm\n",
    "except:\n",
    "    !from pandas_profiling import tqdm   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTUNA_TRIALS_LOGISTIC_REGRESSOR       =   0 # ставлю ноль витков чтобы их не считать а только подгрузить из базы\n",
    "OPTUNA_TRIALS_CATBOOST_CLASSIFIER      =   0 # \n",
    "OPTUNA_TRIALS_LGBM_CLASSIFIER          =   0 # \n",
    "OPTUNA_TRIALS_LOGISTIC_REGRESSOR_BERT  =   0 # \n",
    "OPTUNA_TRIALS_CATBOOST_CLASSIFIER_BERT =   0 # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модуль для использования прогресс-бара, отображающего прогресс функции apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переменные, отвечающие за сценарий дальнейших действий:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL_TIMEOUT = 2 * 50 * 60 # лимит секунд на один виток optuna \n",
    "\n",
    "BERT_ACTIVITY = 'results' # Использование BERT\n",
    "                           # results  - только загрузить данные расчетов в конечную табличку\n",
    "                           # optimize - считать \n",
    "\n",
    "RECALCULATE_EMBEDDINGS = False   # True / False \n",
    "                                # True  - пересчитываем эмбеддинги \n",
    "                                # False - не пересчитываем эмбеддинги, загружаем из файла\n",
    "SAVE_EMBEDDINGS = False # сохранять ли эмбеддинги в файлы если мы таки их пересчитываем\n",
    "\n",
    "BERT_LENGTH_CAP = 512   # предельное число токенов при вычислении эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 34567\n",
    "random.seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "folds_count = 5         # число фолдов кросс-валидации \n",
    "MY_SCORER = 'f1'\n",
    "#Выборка эмбеддингов для теста выгружена в embeddings_test.csv, оно же https://disk.yandex.ru/d/x_4wHdf8BwpVEA, оно же тут:\n",
    "embeddings_test_url = \"https://s724sas.storage.yandex.net/rdisk/3a22512c9b91708ec9a13da95dc6a8d0eebf61917d34d2b06806a67f14261233/644ae47b/xe8uqA8hy1MK5goEVUYEuTsQGs_fv5ogRHB_SAuTHBldI275BiFuvTP8-_Jzwmxc_1yfMzIkA3z2lBOwHJ-pGA==?uid=0&filename=embeddings_test.csv&disposition=attachment&hash=MqD0jcX5cXgioUODnCbE1VI2hrc1dontA5GceKZOM/3eo0J6wFR%2BMKA2t8IHPoGdq/J6bpmRyOJonT3VoXnDag%3D%3D&limit=0&content_type=text%2Fplain&owner_uid=27013839&fsize=831412638&hid=cf18b924a0c2be6f2344e6a2261e35ed&media_type=spreadsheet&tknv=v2&rtoken=l7ugZBUcM8l9&force_default=no&ycrid=na-401ac77e89e337c0a0585fe5c7543822-downloader9f&ts=5fa57c4d5d4c0&s=7cc4a0ab8e2f0ff1ad3d08bd33f27893827bb1434e6f5a8f170a0c660cb72ba8&pb=U2FsdGVkX1-wadVPTqBex_ZjvSA2vIBem1Y25gVg3hT9H9toXJOV7wqi8RNP1i8t7n1RFczaIUHxai4IFqsk6rW76Guft_W0vHnL9x0ImB0\"\n",
    "#Выборка эмбеддингов для обучения выгружена в embeddings_train.csv, оно же https://disk.yandex.ru/d/ksJAE2vwGcABVA, оно же тут:\n",
    "embeddings_train_url= \"https://s507sas.storage.yandex.net/rdisk/ad8653847bf035a53a6fe56ee20ef5b34e80c36b6fe521ff1f6f2ea2ee79d2af/644ae573/xe8uqA8hy1MK5goEVUYEuYS5_6bEpHrXfM4HrNn3CyRDg02MKF0s35R8Q2-V4NHiUPfF1pwMBwzsiMPDUKgZ6A==?uid=0&filename=embeddings_train.csv&disposition=attachment&hash=tFA8JkrVBhQlO9zUjOLBllSVlIa/efPEK53Zl9bUcK5t8lh2uuf32cHmy6/L38nOq/J6bpmRyOJonT3VoXnDag%3D%3D&limit=0&content_type=text%2Fplain&owner_uid=27013839&fsize=4806111658&hid=1e9df2a39f6633340b6b715b22f730c8&media_type=spreadsheet&tknv=v2&rtoken=PjDKEudhbOo1&force_default=no&ycrid=na-4356e4ba268e4537b333011d8f126cc2-downloader5f&ts=5fa57d39e02c0&s=500c0e6c5d781116b0da290564739196df56d9958f0b45d0db6074e9583b925d&pb=U2FsdGVkX1_NFx1tTpGI5P6mvZ8QTv8Xbi5ukxiS3so4_935tvNONM1oQ_wWDM9XbT3gtTjBMSF69hE429I0sp49KO0kkeDk6YYJ12twHaE\"\n",
    "#Выборка эмбеддингов для валидации выгружена в embeddings_valid.csv, оно же https://disk.yandex.ru/d/V919CP6O2LWUtQ, оно же тут:\n",
    "embeddings_valid_url= \"https://s258vla.storage.yandex.net/rdisk/da832bf09d016b0115f50ae07543bb690245dba4ef26a0a9393b2ecccb5d1011/644ae54b/xe8uqA8hy1MK5goEVUYEuftLf7Fs9Cly1Yc6u9aOl5_E7ZMCHgQp5z3AQ0MNWAr9skMJX3lCg3yJv4UOwi8JOg==?uid=0&filename=embeddings_valid.csv&disposition=attachment&hash=BO2C4vlLWXJuEku9Jze9u1UBTcukl1UOK4UIsmt9I1RsB5EvrCqVdwGeGJ7wCFDdq/J6bpmRyOJonT3VoXnDag%3D%3D&limit=0&content_type=text%2Fplain&owner_uid=27013839&fsize=665125229&hid=dbb227e1dfbe23595de6e08070d0a555&media_type=spreadsheet&tknv=v2&rtoken=s0hkqkD4JRrl&force_default=no&ycrid=na-bd7fa769e5aa99c1684813a37c8b57ba-downloader5f&ts=5fa57d13ba8c0&s=ccd72153e82ea64e124bb6b67e9b056fe20a6b1ce48be1cdb3976e400749eaea&pb=U2FsdGVkX1-G821y9EbFk2zqZ80tXpPnEo128ZSY656W2qF4kTz-u2SK9mt8E2bH8AcNC_CFTiGtWxjwOSAKgL0_RcwCNFXrBzVFDg0Bnmg\"\n",
    "\n",
    "# БД для сохранения расчетов optuna trials и подгрузки\n",
    "# стоит на моем домашнем сервачке\n",
    "\n",
    "db_host     = '95.165.137.102'\n",
    "db_port     = '55432'\n",
    "db_database = 'yandex'\n",
    "db_user     = 'yandex'\n",
    "db_password = 'ypSTUD33223'\n",
    "\n",
    "conn_data = {'user':db_user,'password':db_password, 'host':db_host, 'port':db_port, 'database':db_database}\n",
    "storage_url = f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_database}'\n",
    "storage = optuna.storages.RDBStorage(storage_url)\n",
    "study_name_base = 'yp_nlp_pipe_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настройки модели BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_voc_filename              = \"vocab.txt\"\n",
    "bert_model_filename            = \"pytorch_model.bin\"\n",
    "bert_config_filename           = \"config.json\"\n",
    "bert_tokenizer_filename        = \"tokenizer.json\"\n",
    "bert_tokenizer_config_filename = \"tokenizer_config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE    = 'cuda'   # для pytorch\n",
    "    TASK_TYPE = 'GPU' # для catboost\n",
    "else:\n",
    "    DEVICE    = 'cpu'    # для pytorch\n",
    "    TASK_TYPE = 'CPU' # для catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = platform.node()\n",
    "filename = \"toxic_comments.csv\"\n",
    "\n",
    "# На машинах исполнителя проекта файл с данными доступен через символический путь, \n",
    "# ссылающийса на папку на яндекс.диске, где расположен загружаемый файл. \n",
    "# В случае если хостом где выполняется анализ является какая-либо другая машина, \n",
    "# используем путь по умолчанию.\n",
    "try:    \n",
    "    if host.lower() in ['22varivoda','gover-pc','msi','gmain']:\n",
    "        filepath    = r'C:/_YDsymlink/dataSciencePlus/datasets/'\n",
    "        #bert_path   = r'C:/_YDsymlink/Python/datascience/Projects/26 - NLP/ds_bert/bert-large-cased/'\n",
    "        bert_path   = r'C:/_YDsymlink/Python/datascience/Projects/26 - NLP/ds_bert/toxic-bert/'\n",
    "    else:\n",
    "        filepath    = '/datasets/'\n",
    "        bert_path   = r'/datasets/ds_bert/'\n",
    "except:\n",
    "    print(\"Не удалось подгрузить данные\")\n",
    "    \n",
    "pd.reset_option('^display.',silent=True)\n",
    "pd.set_option('display.float_format', str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(filepath+filename, sep=',', index_col=[0], parse_dates=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Классы</B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Трансформер для подготовки признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделей, использующих BERT указываем with_embeddings=True при написании Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareFeatures(BaseEstimator, TransformerMixin):    \n",
    "    def __init__(self, with_embeddings=False ):      \n",
    "        global stop_words\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(stop_words=list(stop_words))\n",
    "        self.with_embeddings  = with_embeddings\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        self.tfidf_vectorizer.fit( X['lemmatized'].values )\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        tf_idf = self.tfidf_vectorizer.transform( X['lemmatized'].values )\n",
    "      \n",
    "        if self.with_embeddings == True:\n",
    "            emb = X.loc[:,'1':'767']\n",
    "            features = hstack( ( tf_idf, emb.values) )\n",
    "        else:\n",
    "            features = tf_idf\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Методы</B>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция отправки сообщений в Telegram (об окончании обучения и т.п.)<BR>\n",
    "Вывод идет сюда: @gover_jupyter_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tprint(message,verb=True):   \n",
    "    # подробнее об этом: https://pythonist.ru/otpravka-soobshhenij-v-telegram-pri-pomoshhi-python/\n",
    "    TOKEN = \"5979454825:AAH8n7awvogIwLyHMk_zeqfVq92n_54e4Bs\" # Мой токен бота для уведомлений\n",
    "    chat_id = \"232987571\"                                    # Мой ID \n",
    "    url = f\"https://api.telegram.org/bot{TOKEN}/sendMessage?chat_id={chat_id}&text={message}\"\n",
    "    requests.get(url).json() # отправка сообщения\n",
    "    if verb:\n",
    "        print(message)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод в HTML-формате для удобства оформления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_html(message): \n",
    "    from IPython.display import display, HTML\n",
    "    out_msg = HTML(message)\n",
    "    display(out_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод информации о витке оптимизации optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_output_trial_info(trial,comment=''): \n",
    "    if comment != '':\n",
    "        print_html(comment)\n",
    "    for key, value in trial.__dict__.items():\n",
    "        if key in ['_distributions','_params']:\n",
    "            print_html(f'<font size=-1><b>{key}</b>: </font>')\n",
    "            for k1, v1 in value.items():\n",
    "                print_html(f\"<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;{k1}:{v1}</font>\")\n",
    "        else:\n",
    "            if type(value) == type(dict()):\n",
    "                if len(value.items()) >= 1:\n",
    "                    print_html(f'<font size=-1><b>{key}</b>: {value}</font>')\n",
    "            else:\n",
    "                print_html(f'<font size=-1><b>{key}</b>: {value}</font>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_memory():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка текстов для использования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_for_ngrams(block, d=d, re=re):\n",
    "    block = block.split()\n",
    "    res = []\n",
    "    tb = ''\n",
    "    for b in block:\n",
    "        tb = re.sub(r'','',b)\n",
    "        tb = re.sub(r'\\d+','',tb)\n",
    "        tb = re.sub(r\"[^A-Za-z\\'\\s\\-]\",'',tb)\n",
    "        #tb = re.sub(r\"^\\s*[BCDEFGHJKLMNPQSTVZbcdefghjklmnpqstvz]{1,1}\\s*$\",' ',tb)                            \n",
    "        tb = re.sub(r\"^['-.,]\",'',tb)        \n",
    "        tb = re.sub(r\"^\\s{1,1}$\",'',tb)        \n",
    "        if tb == '':\n",
    "            continue\n",
    "        # Проверка с помощью pyenchant.check => True (текст является словом на английском)/False (не является словом на английском)        \n",
    "        if d.check(tb) and str.strip(tb) != '': \n",
    "            res.append(tb)\n",
    "    return ' '.join(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lemmatized(block):\n",
    "    res = []\n",
    "    for b in block:\n",
    "        #print(\"b=[\",b,\"] \",end='' )\n",
    "        res_b = re.sub(r'\\d+','',b)\n",
    "        res_b = re.sub(r\"[^A-Za-z\\'\\s\\-]\",'',res_b)\n",
    "        res_b = re.sub(r\"^\\s*\\w{1,1}\\s*$\",' ',res_b)\n",
    "        res_b = re.sub(r\"^['-.,]\",'',res_b)\n",
    "        if len(res_b) >= 2:\n",
    "            res.append(res_b)\n",
    "    return ' '.join(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция подготовки эмбеддингов с помощью BERT<BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(padded, attention_mask, model, device='cpu', batch_size=100):\n",
    "    # чистим память\n",
    "    model.cpu()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # выбираем устройство\n",
    "    model.to(device);\n",
    "    if device.startswith('cuda'):\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    # создаем эмбеддинги\n",
    "    embeddings = []\n",
    "    n_full_batches = padded.shape[0] // batch_size\n",
    "    for i in notebook.tqdm( range(n_full_batches + 1)  ):\n",
    "        if i <= n_full_batches:\n",
    "            batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "            attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        else:\n",
    "            batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1) + padded.shape[0]%batch_size]) \n",
    "            attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1) + padded.shape[0]%batch_size])\n",
    "            \n",
    "        batch = batch.to(device)\n",
    "        attention_mask_batch = attention_mask_batch.to(device)\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch )\n",
    "\n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())\n",
    "                \n",
    "    # снова чистим память\n",
    "    model.cpu()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gmain: НАЧАЛО РАБОТЫ\n"
     ]
    }
   ],
   "source": [
    "tprint(f\"\\n{host}: НАЧАЛО РАБОТЫ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим пример записей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим примеры токсичных записей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This shit is fucking gay you need to get the right information dumb fucks\n",
      "-----\n",
      "Sorry, I looked at the wrong diff and thought the IP was back adding shit.\n",
      "-----\n",
      "Tread along dear boy  \n",
      "\n",
      "Goway ya fool you think your hard!\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for c in data.loc[data['toxic'] == 1].sample(3)['text'].values:\n",
    "    print(c)\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159292.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.10161213369158527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.3021385130396282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    toxic\n",
       "count            159292.0\n",
       "mean  0.10161213369158527\n",
       "std    0.3021385130396282\n",
       "min                   0.0\n",
       "25%                   0.0\n",
       "50%                   0.0\n",
       "75%                   0.0\n",
       "max                   1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка на пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка на дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка на сбалансированность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класс 1 соответствует 16186 записям\n",
      "Класс 0 соответствует 143106 записям\n"
     ]
    }
   ],
   "source": [
    "print(f\"Класс 1 соответствует { len( data.loc[data['toxic'] == 1] )} записям\")\n",
    "print(f\"Класс 0 соответствует { len( data.loc[data['toxic'] == 0] )} записям\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выраженный дисбаланс в сторону нулевого класса! Для моделей не использующих эмбеддинги BERT будем устранять после предобработок (чтобы не делать предобработку одних и тех же блоков несколько раз). Для BERT будем делать подготовку отдельно после."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 24 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120761e959c7453f950d1c2934cc0155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=6638), Label(value='0 / 6638'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.59 s\n",
      "Wall time: 4min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus = data['text'].parallel_apply( clear_for_ngrams )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['corpus']=corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368b0ebddb0b41acb83f0b4eb8a696fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=6638), Label(value='0 / 6638'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.73 s\n",
      "Wall time: 5.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenized = data['text'].parallel_apply(lambda x, nltk=nltk: nltk.tokenize.word_tokenize(x.lower() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokenized'] = tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed280e7b32254d17b539d4aac8f9c3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=6638), Label(value='0 / 6638'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.7 s\n",
      "Wall time: 56.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lemmatized = corpus.parallel_apply(   lambda x, nlp=nlp: \" \".join([token.lemma_ for token in nlp(x)])  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemmatized'] = lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка лемматизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<B>60313) lemmatized</B>    : UTC basically it mean make from a rift which be an argument around a create word where if you say something be it be QED make rift no argument for instance here it be be use to argue that oil be create by mid ocean ridge spread be it up for discussion February"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<B>60313) not lemmatized</B>: UTC Basically it means made from a rift Which is an argument around a created word where if you say something is it is QED made rift No arguments For instance here it is being used to argue that oil is created by mid ocean ridge spreading Is it up for discussion February"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<B>60314) lemmatized</B>    : why be not the article call SLOVENIAN WAR of independence or SLOVENIAN WAR of LIBERATION"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<B>60314) not lemmatized</B>: Why isn't the article called SLOVENIAN WAR OF INDEPENDENCE or SLOVENIAN WAR OF LIBERATION"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<B>60315) lemmatized</B>    : sen T December June Fianna Minister for Local Government and Public Health Minister for Education Minister for Finance President of Ireland"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<B>60315) not lemmatized</B>: Sen T December June Fianna Minister for Local Government and Public Health Minister for Education Minister for Finance President of Ireland"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(data)\n",
    "start_point = randint(0, (dataset_size-3))\n",
    "end_point   = start_point+3\n",
    "for i in range(start_point,end_point):\n",
    "    print_html(f\"<B>{i+1}) lemmatized</B>    : {data.iloc[i]['lemmatized']}\")\n",
    "    print_html(f\"<B>{i+1}) not lemmatized</B>: {data.iloc[i]['corpus']}\")\n",
    "    print(f\"_________________________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Подготовка модели BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель расположена в папке, указанной в переменной bert_path в начале. Используем toxic_bert согласно правке 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используем модель, расположенную в папке: C:/_YDsymlink/Python/datascience/Projects/26 - NLP/ds_bert/toxic-bert/\n"
     ]
    }
   ],
   "source": [
    "print(f\"Используем модель, расположенную в папке: {bert_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BERT_ACTIVITY != 'results':\n",
    "    try:    \n",
    "        if host.lower() in ['22varivoda','gover-pc','msi','gmain']:\n",
    "            tokenizer = transformers.BertTokenizer( vocab_file= bert_path + bert_voc_filename )\n",
    "    \n",
    "            config = transformers.BertConfig.from_json_file( bert_path + bert_config_filename )\n",
    "            model  = transformers.BertModel.from_pretrained( bert_path + bert_model_filename, config=config)\n",
    "        else:\n",
    "            model = transformers.AutoModel.from_pretrained('unitary/toxic-bert')\n",
    "            tokenizer = transformers.AutoTokenizer.from_pretrained('unitary/toxic-bert')\n",
    "    except:\n",
    "        print_html(\"<font color='red'>Could not load BERT model</font>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Подготовка признаков BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmain Пропускаем подготовку признаков BERT\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 201 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    \n",
    "if BERT_ACTIVITY != 'results':    \n",
    "    tprint(f\"{host}: подготовка признаков для BERT\")\n",
    "\n",
    "    max_length = BERT_LENGTH_CAP\n",
    "\n",
    "    # токенизация\n",
    "    tokenized_ = data['text'].parallel_apply( lambda x, tokenizer=tokenizer, max_length=max_length: tokenizer.encode(x, add_special_tokens=True, max_length = max_length))\n",
    "\n",
    "    padded       = np.array([i + [0]*(max_length - len(i)) for i in tokenized_.values])\n",
    "\n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "else:\n",
    "    tprint(f\"{host} Пропускаем подготовку признаков BERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if BERT_ACTIVITY != 'results':\n",
    "    \n",
    "    if RECALCULATE_EMBEDDINGS:\n",
    "        embeddings = get_embeddings(padded, attention_mask, model, device=DEVICE, batch_size=100)\n",
    "        if SAVE_EMBEDDINGS:\n",
    "            savetxt('embeddings.csv', embeddings, delimiter=';')\n",
    "    else:\n",
    "        embeddings = loadtxt('embeddings.csv',delimiter=';')\n",
    "    \n",
    "    # вставляем эмбеддинги в датасет\n",
    "    data = data.reset_index(drop=True).join( pd.DataFrame(embeddings).reset_index(drop=True), lsuffix='_embedding' ) \n",
    "    data.columns = data.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmain: Подготовка признаков для использования BERT завершена\n"
     ]
    }
   ],
   "source": [
    "tprint(f\"{host}: Подготовка признаков для использования BERT завершена\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test  = train_test_split(data,       test_size=0.2, random_state = RANDOM_STATE , stratify=data['toxic']       )\n",
    "data_train, data_valid = train_test_split(data_train, test_size=0.2, random_state = RANDOM_STATE , stratify=data_train['toxic'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчет весов классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(data_train['toxic'])\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=data_train['toxic'])\n",
    "class_weights = dict(zip(classes, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5565527858757248, 1: 4.920648711265566}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переменную class_weight будем в дальнейшем использовать при расчетах гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Табличка для сохранения результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняю лучшие полученные значения для всех моделей в результате многочасового подбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BERT_ACTIVITY == 'results':\n",
    "    best_results.append(['Logistic Regression', 640.51, 0.71])\n",
    "    best_results.append(['CatBoost', 79.70, 0.71])\n",
    "    best_results.append(['LGBM', 495.0, 0.74])\n",
    "    best_results.append(['Logistic Regression + BERT', 607.22, 0.93])\n",
    "    best_results.append(['CatBoost + BERT', 150.85, 0.95])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmain: Перебор гиперпараметров. Всего циклов: 0\n"
     ]
    }
   ],
   "source": [
    "tprint(f\"{host}: ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ\",verb=False)\n",
    "tprint(f\"{host}: Перебор гиперпараметров. Всего циклов: {OPTUNA_TRIALS_LOGISTIC_REGRESSOR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_log_reg(trial):\n",
    "    \n",
    "    lor_C             = trial.suggest_float(\"lor_C\",0.01,100)    \n",
    "    lor_solver        = trial.suggest_categorical(\"lor_solver\",[\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\",\"saga\"])\n",
    "    lor_max_iter      = trial.suggest_int(\"lor_max_iter\",300,1200)\n",
    "    lor_tol           = trial.suggest_float(\"lor_tol\",0.0001,0.001)\n",
    "    lor_fit_intercept = trial.suggest_categorical(\"lor_fit_intercept\",[True,False])\n",
    "    \n",
    "    # правка 1: убрано\n",
    "    #lor_class_weight  = trial.suggest_categorical(\"lor_class_weight\",['balanced'])\n",
    "\n",
    "    classifier_obj = LogisticRegression(\n",
    "        C             = lor_C\n",
    "       ,solver        = lor_solver\n",
    "       ,max_iter      = lor_max_iter\n",
    "       ,tol           = lor_tol\n",
    "       ,fit_intercept = lor_fit_intercept\n",
    "        \n",
    "       # constant\n",
    "       ,random_state  = RANDOM_STATE\n",
    "       # правка 1: добавлено \n",
    "       ,class_weight  = 'balanced'\n",
    "    )    \n",
    "    \n",
    "    # правка 1: убрано:\n",
    "    #f1_average = np.mean( cross_val_score(classifier_obj, features_train, target_train, cv=folds_count, scoring = MY_SCORER ) )    \n",
    "    \n",
    "    # правка 1: добавлено:\n",
    "    pipe = Pipeline(steps=[\n",
    "                          ('prepare_features', PrepareFeatures() ),\n",
    "                          ('linear_model', classifier_obj)\n",
    "    ])\n",
    "    f1_average = np.mean( cross_val_score(pipe, data_train, data_train['toxic'], cv=folds_count, scoring = MY_SCORER ) )    \n",
    "    return f1_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-02 03:34:57,437]\u001b[0m Using an existing study with name 'yp_nlp_pipe_logreg' instead of creating a new one.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_log_regression = optuna.create_study(direction=\"maximize\",study_name=study_name_base + 'logreg', storage=storage, load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запуск цикла подбора гиперпараметров для LogisticRegression. Число витков цикла: 0\n",
      "\n",
      " Перебор гиперпараметров занял 0.00 секунд (0.0 минут / 0.0 часов)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Лучший виток:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_number</b>: 0</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>state</b>: 1</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_values</b>: [0.7037435513281585]</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_datetime_start</b>: 2023-05-01 20:17:06.944842</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>datetime_complete</b>: 2023-05-01 20:17:29.011160</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_params</b>: </font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_C:99.14275235905818</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_class_weight:None</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_fit_intercept:False</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_max_iter:635</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_solver:newton-cg</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_tol:0.0005506593403540723</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_distributions</b>: </font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_C:FloatDistribution(high=100.0, log=False, low=0.01, step=None)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_class_weight:CategoricalDistribution(choices=('balanced', None))</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_fit_intercept:CategoricalDistribution(choices=(True, False))</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_max_iter:IntDistribution(high=1000, log=False, low=100, step=1)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_solver:CategoricalDistribution(choices=('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'))</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_tol:FloatDistribution(high=0.001, log=False, low=0.0001, step=None)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_trial_id</b>: 35</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(f\"Запуск цикла подбора гиперпараметров для LogisticRegression. Число витков цикла: {OPTUNA_TRIALS_LOGISTIC_REGRESSOR}\")\n",
    "study_log_regression.optimize(objective_log_reg, timeout=TRIAL_TIMEOUT, n_trials = OPTUNA_TRIALS_LOGISTIC_REGRESSOR)\n",
    "\n",
    "end = time.time()\n",
    "duration_log_reg = end - start\n",
    "\n",
    "print ('\\n Перебор гиперпараметров занял %0.2f секунд (%0.1f минут / %0.1f часов)'%(duration_log_reg, duration_log_reg/60, duration_log_reg/3600) )\n",
    "\n",
    "my_output_trial_info(study_log_regression.best_trial,'Лучший виток:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lor = study_log_regression.best_params\n",
    "best_score_lor  = study_log_regression.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmain: model = LogisticRegression: Перебор гиперпараметров занял 0.00 секунд (0.0 минут / 0.0 часов)\n",
      "Метрика: 0.7037435513281585\n",
      "Гиперпараметры: {'lor_C': 99.14275235905818, 'lor_class_weight': None, 'lor_fit_intercept': False, 'lor_max_iter': 635, 'lor_solver': 'newton-cg', 'lor_tol': 0.0005506593403540723}\n",
      "Секунд на один виток: 0\n"
     ]
    }
   ],
   "source": [
    "if OPTUNA_TRIALS_LOGISTIC_REGRESSOR != 0:\n",
    "    sec_per_trial_log_reg = duration_log_reg/OPTUNA_TRIALS_LOGISTIC_REGRESSOR\n",
    "else:\n",
    "    sec_per_trial_log_reg = 0\n",
    "tprint(f'{host}: model = LogisticRegression: Перебор гиперпараметров занял %0.2f секунд (%0.1f минут / %0.1f часов)'%(duration_log_reg, duration_log_reg/60, duration_log_reg/3600)+f\"\\nМетрика: {best_score_lor}\"\n",
    "       +f\"\\nГиперпараметры: {best_params_lor}\\nСекунд на один виток: { sec_per_trial_log_reg }\"      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_regressor = LogisticRegression(\n",
    "        C             = best_params_lor['lor_C']\n",
    "       ,solver        = best_params_lor['lor_solver']\n",
    "       ,max_iter      = best_params_lor['lor_max_iter']\n",
    "       ,tol           = best_params_lor['lor_tol']\n",
    "       ,fit_intercept = best_params_lor['lor_fit_intercept']\n",
    "       #,class_weight  = best_params_lor['lor_class_weight']   # <-- правка 1: убрано\n",
    "    \n",
    "        # constant\n",
    "       ,random_state  = RANDOM_STATE\n",
    "       ,class_weight  = 'balanced'     # <-- правка 1: добавлено\n",
    "    )    \n",
    "# правка 1: добавлено:\n",
    "model_log_regressor = Pipeline(steps=[\n",
    "                      ('prepare_features', PrepareFeatures() ),\n",
    "                      ('linear_model', model_log_regressor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmain: Метрика LogisticRegression на валидации: 0.6622116149562451\n"
     ]
    }
   ],
   "source": [
    "model_log_regressor.fit(data_train,data_train['toxic'])\n",
    "pred_valid_logreg = model_log_regressor.predict(data_valid)\n",
    "metric_valid_logreg = f1_score(data_valid['toxic'],pred_valid_logreg)\n",
    "tprint(f'{host}: Метрика LogisticRegression на валидации: {metric_valid_logreg}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем в табличку результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_row = ['Logistic Regression',duration_log_reg,metric_valid_logreg]\n",
    "already_exists = False\n",
    "for i in range(0,len(best_results)):\n",
    "    if best_results[i][0] == 'Logistic Regression':\n",
    "        if best_results[i][2] < best_score_lor:\n",
    "            best_results[i] = set_row\n",
    "            already_exists = True\n",
    "if not already_exists:\n",
    "    best_results.append(set_row)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmain: Перебор гиперпараметров. Всего циклов: 0\n"
     ]
    }
   ],
   "source": [
    "tprint(f\"{host}: CATBOOST CLASSIFIER\",verb=False)\n",
    "tprint(f\"{host}: Перебор гиперпараметров. Всего циклов: {OPTUNA_TRIALS_CATBOOST_CLASSIFIER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь не хватает памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cb(trial):\n",
    "    global class_weights\n",
    "    \n",
    "    cb_learning_rate       = trial.suggest_float(\"cb_learning_rate\", 0.04, 0.2)  # 0.01, 0.2\n",
    "    cb_depth               = trial.suggest_int(\"cb_depth\", 4,7)    # 4, 10\n",
    "    cb_l2_leaf_reg         = trial.suggest_float(\"cb_l2_leaf_reg\",1,10)\n",
    "    cb_iterations          = trial.suggest_int(\"cb_iterations\",100,600)  # 100, 1000\n",
    "   \n",
    "    classifier_obj = CatBoostClassifier(\n",
    "         learning_rate       = cb_learning_rate\n",
    "        ,depth               = cb_depth\n",
    "        ,iterations          = cb_iterations\n",
    "        ,l2_leaf_reg         = cb_l2_leaf_reg\n",
    "        \n",
    "         #constant\n",
    "        ,task_type   = TASK_TYPE\n",
    "        ,random_seed = RANDOM_STATE\n",
    "        ,verbose=False\n",
    "        \n",
    "        # правка 1: добавлено:\n",
    "        ,class_weights=class_weights\n",
    "    )    \n",
    "    \n",
    "    # правка 1: убрано:\n",
    "    #f1_average = np.mean( cross_val_score(classifier_obj, features_train, target_train, cv=folds_count, scoring = MY_SCORER ) )    \n",
    "    \n",
    "    # правка 1: добавлено:\n",
    "    pipe = Pipeline(steps=[\n",
    "                          ('prepare_features', PrepareFeatures() ),\n",
    "                          ('catboost_model', classifier_obj)\n",
    "    ])\n",
    "    f1_average = np.mean( cross_val_score(pipe, data_train, data_train['toxic'], cv=folds_count, scoring = MY_SCORER ) )    \n",
    "    return f1_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-02 03:35:04,756]\u001b[0m Using an existing study with name 'yp_nlp_pipe_catboost' instead of creating a new one.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_catboost_classifier = optuna.create_study(direction=\"maximize\",study_name=study_name_base + 'catboost', storage=storage, load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запуск цикла подбора гиперпараметров для CatBoostClassifier. Число витков цикла: 0. Лимит на виток: 6000 сек.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(f\"Запуск цикла подбора гиперпараметров для CatBoostClassifier. Число витков цикла: {OPTUNA_TRIALS_CATBOOST_CLASSIFIER}. Лимит на виток: {TRIAL_TIMEOUT} сек.\")\n",
    "study_catboost_classifier.optimize(objective_cb, timeout=TRIAL_TIMEOUT , n_trials=OPTUNA_TRIALS_CATBOOST_CLASSIFIER)\n",
    "\n",
    "end = time.time()\n",
    "duration_cb = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Перебор гиперпараметров занял 0.00 секунд (0.0 минут / 0.0 часов)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<BR>Лучший виток:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_number</b>: 3</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>state</b>: 1</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_values</b>: [0.7215140879372505]</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_datetime_start</b>: 2023-05-01 22:52:00.650152</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>datetime_complete</b>: 2023-05-01 22:53:20.267483</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_params</b>: </font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;cb_depth:4</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;cb_iterations:139</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;cb_l2_leaf_reg:1.0081656967993826</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;cb_learning_rate:0.13210860389051202</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_distributions</b>: </font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;cb_depth:IntDistribution(high=7, log=False, low=4, step=1)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;cb_iterations:IntDistribution(high=600, log=False, low=100, step=1)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;cb_l2_leaf_reg:FloatDistribution(high=10.0, log=False, low=1.0, step=None)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;cb_learning_rate:FloatDistribution(high=0.2, log=False, low=0.04, step=None)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_trial_id</b>: 64</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tprint ('\\n Перебор гиперпараметров занял %0.2f секунд (%0.1f минут / %0.1f часов)'%(duration_cb, duration_cb/60, duration_cb/3600) )\n",
    "\n",
    "my_output_trial_info(study_catboost_classifier.best_trial,'<BR>Лучший виток:')\n",
    "\n",
    "best_params_cb = study_catboost_classifier.best_params\n",
    "best_score_cb  = study_catboost_classifier.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmain: model = CatBoostClassifier: Перебор гиперпараметров занял 0.00 секунд (0.0 минут / 0.0 часов)\n",
      "Метрика: 0.7215140879372505\n",
      "Гиперпараметры: {'cb_depth': 4, 'cb_iterations': 139, 'cb_l2_leaf_reg': 1.0081656967993826, 'cb_learning_rate': 0.13210860389051202}\n",
      "Секунд на один виток: 0\n"
     ]
    }
   ],
   "source": [
    "if OPTUNA_TRIALS_CATBOOST_CLASSIFIER != 0:\n",
    "    sec_per_trial_cb = duration_cb/OPTUNA_TRIALS_CATBOOST_CLASSIFIER\n",
    "else:\n",
    "    sec_per_trial_cb = 0\n",
    "tprint(f'{host}: model = CatBoostClassifier: Перебор гиперпараметров занял %0.2f секунд (%0.1f минут / %0.1f часов)'%(duration_cb, duration_cb/60, duration_cb/3600)+f\"\\nМетрика: {best_score_cb}\"\n",
    "       +f\"\\nГиперпараметры: {best_params_cb}\\nСекунд на один виток: { sec_per_trial_cb }\"      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_catboost = CatBoostClassifier(\n",
    "     learning_rate       = best_params_cb['cb_learning_rate']    \n",
    "    ,depth               = best_params_cb['cb_depth']\n",
    "    ,l2_leaf_reg         = best_params_cb['cb_l2_leaf_reg']\n",
    "    ,iterations          = best_params_cb['cb_iterations']\n",
    "    \n",
    "    #constant\n",
    "    ,task_type   = TASK_TYPE\n",
    "    ,random_seed = RANDOM_STATE\n",
    "    ,verbose=False\n",
    "    \n",
    "    # правка 1: добавлено\n",
    "    ,class_weights=class_weights\n",
    ")   \n",
    "# правка 1: добавлено:\n",
    "model_catboost = Pipeline(steps=[\n",
    "                      ('prepare_features', PrepareFeatures() ),\n",
    "                      ('catboost_model', model_catboost)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmain: Метрика CatBoostClassifier на валидации: 0.7145969498910676\n"
     ]
    }
   ],
   "source": [
    "model_catboost.fit(data_train,data_train['toxic'])\n",
    "pred_valid_cb = model_catboost.predict(data_valid)\n",
    "metric_valid_cb = f1_score(data_valid['toxic'],pred_valid_cb)\n",
    "tprint(f'{host}: Метрика CatBoostClassifier на валидации: {metric_valid_cb}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем в табличку результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_row = ['CatBoost',duration_cb, metric_valid_cb]\n",
    "already_exists = False\n",
    "for i in range(0,len(best_results)):\n",
    "    if best_results[i][0] == 'CatBoost':\n",
    "        if best_results[i][2] < best_score_cb:\n",
    "            best_results[i] = set_row\n",
    "            already_exists = True\n",
    "if not already_exists:\n",
    "    best_results.append(set_row)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmain: Перебор гиперпараметров. Всего циклов: 0\n"
     ]
    }
   ],
   "source": [
    "tprint(f\"{host}: LGBM CLASSIFIER\",verb=False)\n",
    "tprint(f\"{host}: Перебор гиперпараметров. Всего циклов: {OPTUNA_TRIALS_LGBM_CLASSIFIER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm(trial):\n",
    "    global class_weights   # <-- правка 1: добавлено\n",
    "    \n",
    "    lgbm_num_leaves        = trial.suggest_int(\"num_leaves\",         20, 1000)\n",
    "    lgbm_learning_rate     = trial.suggest_float(\"learning_rate\", 0.001, 0.1 )\n",
    "    lgbm_max_depth         = trial.suggest_int(\"max_depth\",           5,  50 )\n",
    "    lgbm_reg_alpha         = trial.suggest_float(\"reg_alpha\",         0,  10 )\n",
    "    lgbm_reg_lambda        = trial.suggest_float(\"reg_lambda\",        0,  10 )  \n",
    "    lgbm_n_estimators      = trial.suggest_int(\"n_estimators\",     50,  1000 )  \n",
    "    \n",
    "    classifier_obj = LGBMClassifier(\n",
    "         num_leaves        = lgbm_num_leaves\n",
    "        ,learning_rate     = lgbm_learning_rate\n",
    "        ,max_depth         = lgbm_max_depth\n",
    "        ,reg_alpha         = lgbm_reg_alpha\n",
    "        ,reg_lambda        = lgbm_reg_lambda        \n",
    "        ,n_estimators      = lgbm_n_estimators\n",
    "        \n",
    "         #constant\n",
    "        ,random_seed = RANDOM_STATE\n",
    "        ,verbose     = -1\n",
    "        \n",
    "        # правка 1: добавлено:\n",
    "        ,class_weight= class_weights\n",
    "    )    \n",
    "\n",
    "    # правка 1: убрано:\n",
    "    #f1_average = np.mean( cross_val_score(classifier_obj, features_train, target_train, cv=folds_count, scoring = MY_SCORER ) )    \n",
    "    \n",
    "    # правка 1: добавлено:\n",
    "    pipe = Pipeline(steps=[\n",
    "                          ('prepare_features', PrepareFeatures() ),\n",
    "                          ('lgbm_model', classifier_obj)\n",
    "    ])\n",
    "    f1_average = np.mean( cross_val_score(pipe, data_train, data_train['toxic'], cv=folds_count, scoring = MY_SCORER ) )    \n",
    "    return f1_average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-02 03:35:23,309]\u001b[0m Using an existing study with name 'yp_nlp_pipe_lgbm' instead of creating a new one.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_lgbm_classifier = optuna.create_study(direction=\"maximize\",study_name=study_name_base + 'lgbm', storage=storage, load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запуск цикла подбора гиперпараметров для LGBMClassifier. Число витков цикла: 0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tprint(f\"Запуск цикла подбора гиперпараметров для LGBMClassifier. Число витков цикла: {OPTUNA_TRIALS_LGBM_CLASSIFIER}\")\n",
    "study_lgbm_classifier.optimize(objective_lgbm, timeout=TRIAL_TIMEOUT, n_trials = OPTUNA_TRIALS_LGBM_CLASSIFIER)\n",
    "\n",
    "end = time.time()\n",
    "duration_lgbm = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Перебор гиперпараметров занял 0.18 секунд (0.0 минут / 0.0 часов)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<BR>Лучший виток:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_number</b>: 0</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>state</b>: 1</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_values</b>: [0.745063916014952]</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_datetime_start</b>: 2023-05-01 20:46:15.850059</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>datetime_complete</b>: 2023-05-01 20:51:02.942991</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_params</b>: </font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;learning_rate:0.0842233597772604</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;max_depth:21</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;n_estimators:830</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;num_leaves:780</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;reg_alpha:2.435557863864698</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda:2.0448070636382463</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_distributions</b>: </font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;learning_rate:FloatDistribution(high=0.1, log=False, low=0.001, step=None)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;max_depth:IntDistribution(high=50, log=False, low=5, step=1)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;n_estimators:IntDistribution(high=1000, log=False, low=50, step=1)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;num_leaves:IntDistribution(high=1000, log=False, low=20, step=1)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;reg_alpha:FloatDistribution(high=10.0, log=False, low=0.0, step=None)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;reg_lambda:FloatDistribution(high=10.0, log=False, low=0.0, step=None)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_trial_id</b>: 40</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print ('\\n Перебор гиперпараметров занял %0.2f секунд (%0.1f минут / %0.1f часов)'%(duration_lgbm, duration_lgbm/60, duration_lgbm/3600) )\n",
    "\n",
    "my_output_trial_info(study_lgbm_classifier.best_trial,'<BR>Лучший виток:')\n",
    "\n",
    "best_params_lgbm = study_lgbm_classifier.best_params\n",
    "best_score_lgbm  = study_lgbm_classifier.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmain: model = LGBMClassifier: Перебор гиперпараметров занял 0.18 секунд (0.0 минут / 0.0 часов)\n",
      "Метрика: 0.745063916014952\n",
      "Гиперпараметры: {'learning_rate': 0.0842233597772604, 'max_depth': 21, 'n_estimators': 830, 'num_leaves': 780, 'reg_alpha': 2.435557863864698, 'reg_lambda': 2.0448070636382463}\n",
      "Секунд на один виток: 0\n"
     ]
    }
   ],
   "source": [
    "if OPTUNA_TRIALS_LGBM_CLASSIFIER != 0:\n",
    "    sec_per_trial_lgbm = duration_lgbm/OPTUNA_TRIALS_LGBM_CLASSIFIER\n",
    "else:\n",
    "    sec_per_trial_lgbm = 0\n",
    "tprint(f'{host}: model = LGBMClassifier: Перебор гиперпараметров занял %0.2f секунд (%0.1f минут / %0.1f часов)'%(duration_lgbm, duration_lgbm/60, duration_lgbm/3600)+f\"\\nМетрика: {best_score_lgbm}\"\n",
    "       +f\"\\nГиперпараметры: {best_params_lgbm}\\nСекунд на один виток: { sec_per_trial_lgbm }\"      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgbm = LGBMClassifier(\n",
    "     num_leaves        = best_params_lgbm['num_leaves']\n",
    "    ,learning_rate     = best_params_lgbm['learning_rate']\n",
    "    ,max_depth         = best_params_lgbm['max_depth']\n",
    "    ,reg_alpha         = best_params_lgbm['reg_alpha']\n",
    "    ,reg_lambda        = best_params_lgbm['reg_lambda']    \n",
    "    ,n_estimators      = best_params_lgbm['n_estimators']\n",
    "\n",
    "     #constant\n",
    "    ,random_state = RANDOM_STATE\n",
    "    ,verbose      = -1\n",
    "    \n",
    "    # правка 1: добавлено\n",
    "    ,class_weight = class_weights\n",
    ") \n",
    "# правка 1: добавлено:\n",
    "model_lgbm = Pipeline(steps=[\n",
    "                      ('prepare_features', PrepareFeatures() ),\n",
    "                      ('lgbm_model', model_lgbm)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmain: Метрика LGBMClassifier на валидации: 0.7427085268437674\n"
     ]
    }
   ],
   "source": [
    "model_lgbm.fit(data_train,data_train['toxic'])\n",
    "pred_valid_lgbm = model_lgbm.predict(data_valid)\n",
    "metric_valid_lgbm = f1_score(data_valid['toxic'],pred_valid_lgbm)\n",
    "tprint(f'{host}: Метрика LGBMClassifier на валидации: {metric_valid_lgbm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем в табличку результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_row = ['LGBM',duration_lgbm,metric_valid_lgbm]\n",
    "already_exists = False\n",
    "for i in range(0,len(best_results)):\n",
    "    if best_results[i][0] == 'LGBM':\n",
    "        if best_results[i][2] < best_score_lgbm:\n",
    "            best_results[i] = set_row\n",
    "            already_exists = True\n",
    "if not already_exists:\n",
    "    best_results.append(set_row)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression + BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmain: Перебор гиперпараметров. Всего циклов: 0\n"
     ]
    }
   ],
   "source": [
    "tprint(f\"{host}: ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ + BERT\",verb=False)\n",
    "tprint(f\"{host}: Перебор гиперпараметров. Всего циклов: {OPTUNA_TRIALS_LOGISTIC_REGRESSOR_BERT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если расчет с использованием признаков BERT не делаем, то просто подгружаем ранее обработанные сеансы optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BERT_ACTIVITY == 'results':    \n",
    "    OPTUNA_TRIALS_LOGISTIC_REGRESSOR_BERT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_log_reg_bert(trial):\n",
    "    \n",
    "    lor_C             = trial.suggest_float(\"lor_C\",0.01,100)    \n",
    "    lor_solver        = trial.suggest_categorical(\"lor_solver\",[\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\",\"saga\"])\n",
    "    lor_max_iter      = trial.suggest_int(\"lor_max_iter\",100,2000)\n",
    "    lor_tol           = trial.suggest_float(\"lor_tol\",0.0001,0.001)\n",
    "    lor_fit_intercept = trial.suggest_categorical(\"lor_fit_intercept\",[True,False])\n",
    "    #lor_class_weight  = trial.suggest_categorical(\"lor_class_weight\",['balanced',None]) # <-- правка 1: убрано\n",
    "\n",
    "    classifier_obj = LogisticRegression(\n",
    "        C             = lor_C\n",
    "       ,solver        = lor_solver\n",
    "       ,max_iter      = lor_max_iter\n",
    "       ,tol           = lor_tol\n",
    "       ,fit_intercept = lor_fit_intercept\n",
    "       #,class_weight  = lor_class_weight  # <-- правка 1: убрано\n",
    "        \n",
    "        # constant\n",
    "       ,random_state  = RANDOM_STATE\n",
    "       ,class_weight  = 'balanced'  # <-- правка 1: добавлено\n",
    "    )    \n",
    "    \n",
    "    pipe = Pipeline(steps=[\n",
    "                          ('prepare_features', PrepareFeatures(with_embeddings=True) ),\n",
    "                          ('linear_model', classifier_obj)\n",
    "    ])\n",
    "    f1_average = np.mean( cross_val_score(pipe, data_train, data_train['toxic'], cv=folds_count, scoring = MY_SCORER ) )    \n",
    "    return f1_average\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-02 03:36:37,220]\u001b[0m Using an existing study with name 'yp_nlp_pipe_logreg_bert' instead of creating a new one.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_log_regression_bert = optuna.create_study(direction=\"maximize\",study_name=study_name_base + 'logreg_bert', storage=storage, load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запуск цикла подбора гиперпараметров для LogisticRegression. Число витков цикла: 0\n",
      "\n",
      " Перебор гиперпараметров занял 0.50 секунд (0.0 минут / 0.0 часов)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Лучший виток:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_number</b>: 3</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>state</b>: 1</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_values</b>: [0.9337268912265536]</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_datetime_start</b>: 2023-05-02 02:01:52.379273</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>datetime_complete</b>: 2023-05-02 02:11:59.043886</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_params</b>: </font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_C:57.06878048498513</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_fit_intercept:False</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_max_iter:1888</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_solver:sag</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_tol:0.0007703602898432008</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_distributions</b>: </font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_C:FloatDistribution(high=100.0, log=False, low=0.01, step=None)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_fit_intercept:CategoricalDistribution(choices=(True, False))</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_max_iter:IntDistribution(high=2000, log=False, low=100, step=1)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_solver:CategoricalDistribution(choices=('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'))</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;lor_tol:FloatDistribution(high=0.001, log=False, low=0.0001, step=None)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_trial_id</b>: 72</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(f\"Запуск цикла подбора гиперпараметров для LogisticRegression. Число витков цикла: {OPTUNA_TRIALS_LOGISTIC_REGRESSOR_BERT}\")\n",
    "study_log_regression_bert.optimize(objective_log_reg_bert, timeout=TRIAL_TIMEOUT, n_trials = OPTUNA_TRIALS_LOGISTIC_REGRESSOR_BERT)\n",
    "\n",
    "end = time.time()+ 0.5\n",
    "duration_log_reg_bert = end - start\n",
    "\n",
    "print ('\\n Перебор гиперпараметров занял %0.2f секунд (%0.1f минут / %0.1f часов)'%(duration_log_reg_bert, duration_log_reg_bert/60, duration_log_reg_bert/3600) )\n",
    "\n",
    "my_output_trial_info(study_log_regression_bert.best_trial,'Лучший виток:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lor_bert = study_log_regression_bert.best_params\n",
    "best_score_lor_bert  = study_log_regression_bert.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmain: model = LogisticRegression + BERT: Перебор гиперпараметров занял 0.50 секунд (0.0 минут / 0.0 часов)\n",
      "Метрика: 0.9337268912265536\n",
      "Гиперпараметры: {'lor_C': 57.06878048498513, 'lor_fit_intercept': False, 'lor_max_iter': 1888, 'lor_solver': 'sag', 'lor_tol': 0.0007703602898432008}\n",
      "Секунд на один виток: 0\n"
     ]
    }
   ],
   "source": [
    "if OPTUNA_TRIALS_LOGISTIC_REGRESSOR_BERT != 0:\n",
    "    sec_per_trial_log_reg_bert = duration_log_reg_bert/OPTUNA_TRIALS_LOGISTIC_REGRESSOR_BERT\n",
    "else:\n",
    "    sec_per_trial_log_reg_bert = 0\n",
    "tprint(f'{host}: model = LogisticRegression + BERT: Перебор гиперпараметров занял %0.2f секунд (%0.1f минут / %0.1f часов)'%(duration_log_reg_bert, duration_log_reg_bert/60, duration_log_reg_bert/3600)+f\"\\nМетрика: {best_score_lor_bert}\"\n",
    "       +f\"\\nГиперпараметры: {best_params_lor_bert}\\nСекунд на один виток: { sec_per_trial_log_reg_bert  }\"      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BERT_ACTIVITY != 'results':    \n",
    "    model_log_regressor_bert = LogisticRegression(\n",
    "            C             = best_params_lor_bert['lor_C']\n",
    "           ,solver        = best_params_lor_bert['lor_solver']\n",
    "           ,max_iter      = best_params_lor_bert['lor_max_iter']\n",
    "           ,tol           = best_params_lor_bert['lor_tol']\n",
    "           ,fit_intercept = best_params_lor_bert['lor_fit_intercept']\n",
    "           #,class_weight  = best_params_lor_bert['lor_class_weight']    # <-- правка 1: убрано\n",
    "\n",
    "            # constant\n",
    "           ,random_state  = RANDOM_STATE\n",
    "           ,class_weight  = 'balanced' # <-- правка 1: добавлено\n",
    "        )    \n",
    "    \n",
    "    model_log_regressor_bert = Pipeline(steps=[\n",
    "                      ('prepare_features', PrepareFeatures(with_embeddings=True) ),\n",
    "                      ('linear_model', model_log_regressor_bert)\n",
    "    ])\n",
    "\n",
    "    model_log_regressor_bert.fit(data_train,data_train['toxic'])\n",
    "    pred_valid_logreg_bert = model_log_regressor_bert.predict(data_valid)\n",
    "    metric_valid_logreg_bert = f1_score(data_valid['toxic'],pred_valid_logreg_bert)\n",
    "    tprint(f'{host}: Метрика LogisticRegression + BERT на валидации: {metric_valid_logreg_bert}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем в табличку результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BERT_ACTIVITY != 'results':    \n",
    "\n",
    "    set_row = ['Logistic Regression + BERT',duration_log_reg_bert,metric_valid_logreg_bert]\n",
    "    already_exists = False\n",
    "    for i in range(0,len(best_results)):\n",
    "        if best_results[i][0] == 'Logistic Regression + BERT':\n",
    "            if best_results[i][2] < best_score_lor_bert:\n",
    "                best_results[i] = set_row\n",
    "                already_exists = True\n",
    "    if not already_exists:\n",
    "        best_results.append(set_row)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Catboost + BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmain: Перебор гиперпараметров. Всего циклов: 0\n"
     ]
    }
   ],
   "source": [
    "tprint(f\"{host}: CATBOOST CLASSIFIER + BERT\",verb=False)\n",
    "tprint(f\"{host}: Перебор гиперпараметров. Всего циклов: {OPTUNA_TRIALS_CATBOOST_CLASSIFIER_BERT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если расчет с использованием признаков BERT не делаем, то просто подгружаем ранее обработанные сеансы optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BERT_ACTIVITY == 'results':    \n",
    "    OPTUNA_TRIALS_CATBOOST_CLASSIFIER_BERT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cb_bert(trial):\n",
    "    \n",
    "    cb_learning_rate       = trial.suggest_float(\"cb_learning_rate\", 0.04, 0.2)  # 0.01, 0.2\n",
    "    cb_depth               = trial.suggest_int(\"cb_depth\", 4,7)    # 4, 10\n",
    "    cb_l2_leaf_reg         = trial.suggest_float(\"cb_l2_leaf_reg\",1,10)\n",
    "    cb_iterations          = trial.suggest_int(\"cb_iterations\",100,600)  # 100, 1000\n",
    "   \n",
    "    classifier_obj = CatBoostClassifier(\n",
    "         learning_rate       = cb_learning_rate\n",
    "        ,depth               = cb_depth\n",
    "        ,iterations          = cb_iterations\n",
    "        ,l2_leaf_reg         = cb_l2_leaf_reg\n",
    "        \n",
    "         #constant\n",
    "        ,task_type   = TASK_TYPE\n",
    "        ,random_seed = RANDOM_STATE\n",
    "        ,verbose=False\n",
    "\n",
    "        ,class_weights=class_weights\n",
    "    )    \n",
    "    \n",
    "    pipe = Pipeline(steps=[\n",
    "                          ('prepare_features', PrepareFeatures(with_embeddings=True) ),\n",
    "                          ('catboost_model', classifier_obj)\n",
    "    ])\n",
    "    f1_average = np.mean( cross_val_score(pipe, data_train, data_train['toxic'], cv=folds_count, scoring = MY_SCORER ) )    \n",
    "    return f1_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-02 03:36:38,226]\u001b[0m Using an existing study with name 'yp_nlp_pipe_catboost_bert' instead of creating a new one.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_catboost_classifier_bert = optuna.create_study(direction=\"maximize\",study_name=study_name_base + 'catboost_bert', storage=storage, load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запуск цикла подбора гиперпараметров для CatBoostClassifier + BERT. Число витков цикла: 0. Лимит на виток: 6000 сек.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(f\"Запуск цикла подбора гиперпараметров для CatBoostClassifier + BERT. Число витков цикла: {OPTUNA_TRIALS_CATBOOST_CLASSIFIER_BERT}. Лимит на виток: {TRIAL_TIMEOUT} сек.\")\n",
    "tqdm(study_catboost_classifier_bert.optimize(objective_cb_bert, timeout=TRIAL_TIMEOUT , n_trials=OPTUNA_TRIALS_CATBOOST_CLASSIFIER_BERT))\n",
    "\n",
    "end = time.time()\n",
    "duration_cb_bert = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Перебор гиперпараметров занял 0.00 секунд (0.0 минут / 0.0 часов)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<BR>Лучший виток:"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_number</b>: 1</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>state</b>: 1</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_values</b>: [0.9217765587341618]</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_datetime_start</b>: 2023-05-02 02:18:49.937155</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>datetime_complete</b>: 2023-05-02 02:21:20.716917</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_params</b>: </font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;cb_depth:6</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;cb_iterations:188</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;cb_l2_leaf_reg:2.82652277273253</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;cb_learning_rate:0.12234701226174474</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_distributions</b>: </font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;cb_depth:IntDistribution(high=7, log=False, low=4, step=1)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;cb_iterations:IntDistribution(high=600, log=False, low=100, step=1)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;cb_l2_leaf_reg:FloatDistribution(high=10.0, log=False, low=1.0, step=None)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1>&nbsp;&nbsp;&nbsp;&nbsp;cb_learning_rate:FloatDistribution(high=0.2, log=False, low=0.04, step=None)</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<font size=-1><b>_trial_id</b>: 73</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tprint ('\\n Перебор гиперпараметров занял %0.2f секунд (%0.1f минут / %0.1f часов)'%(duration_cb_bert, duration_cb_bert/60, duration_cb_bert/3600) )\n",
    "\n",
    "my_output_trial_info(study_catboost_classifier_bert.best_trial,'<BR>Лучший виток:')\n",
    "\n",
    "best_params_cb_bert = study_catboost_classifier_bert.best_params\n",
    "best_score_cb_bert  = study_catboost_classifier_bert.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmain: model = CatboostClassifier + BERT: Перебор гиперпараметров занял 0.00 секунд (0.0 минут / 0.0 часов)\n",
      "Метрика: 0.9217765587341618\n",
      "Гиперпараметры: {'cb_depth': 6, 'cb_iterations': 188, 'cb_l2_leaf_reg': 2.82652277273253, 'cb_learning_rate': 0.12234701226174474}\n",
      "Секунд на один виток: 0\n"
     ]
    }
   ],
   "source": [
    "if OPTUNA_TRIALS_CATBOOST_CLASSIFIER_BERT != 0:\n",
    "    sec_per_trial_cb_bert = duration_cb_bert/OPTUNA_TRIALS_CATBOOST_CLASSIFIER_BERT\n",
    "else:\n",
    "    sec_per_trial_cb_bert = 0\n",
    "tprint(f'{host}: model = CatboostClassifier + BERT: Перебор гиперпараметров занял %0.2f секунд (%0.1f минут / %0.1f часов)'%(duration_cb_bert, duration_cb_bert/60, duration_cb_bert/3600)+f\"\\nМетрика: {best_score_cb_bert}\"\n",
    "       +f\"\\nГиперпараметры: {best_params_cb_bert}\\nСекунд на один виток: { sec_per_trial_cb_bert  }\"      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BERT_ACTIVITY != 'results':  \n",
    "\n",
    "    model_catboost_bert = CatBoostClassifier(\n",
    "         learning_rate       = best_params_cb_bert['cb_learning_rate']    \n",
    "        ,depth               = best_params_cb_bert['cb_depth']\n",
    "        ,l2_leaf_reg         = best_params_cb_bert['cb_l2_leaf_reg']\n",
    "        ,iterations          = best_params_cb_bert['cb_iterations']\n",
    "\n",
    "        #constant\n",
    "        ,task_type   = TASK_TYPE\n",
    "        ,random_seed = RANDOM_STATE\n",
    "        ,verbose = False\n",
    "    )   \n",
    "    \n",
    "    model_catboost_bert = Pipeline(steps=[\n",
    "                          ('prepare_features', PrepareFeatures(with_embeddings=True) ),\n",
    "                          ('catboost_model', model_catboost_bert)\n",
    "    ])\n",
    "    \n",
    "    model_catboost_bert.fit(data_train,data_train['toxic'])\n",
    "    pred_valid_cb_bert = model_catboost_bert.predict(data_valid)\n",
    "    metric_valid_cb_bert = f1_score(data_valid['toxic'],pred_valid_cb_bert)\n",
    "    tprint(f'{host}: Метрика CatBoostClassifier + BERT на валидации: {metric_valid_cb_bert}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем в табличку результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BERT_ACTIVITY != 'results':  \n",
    "\n",
    "    set_row = ['CatBoost + BERT',duration_cb_bert, metric_valid_cb_bert]\n",
    "    already_exists = False\n",
    "    for i in range(0,len(best_results)):\n",
    "        if best_results[i][0] == 'CatBoost + BERT':\n",
    "            if best_results[i][2] < best_score_cb:\n",
    "                best_results[i] = set_row\n",
    "                already_exists = True\n",
    "    if not already_exists:\n",
    "        best_results.append(set_row)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprint(f\"{host}: ТЕСТИРОВАНИЕ\",verb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = ['Модель','Время подготовки модели (c)','Метрика валидации (F1)']\n",
    "best_results_df = pd.DataFrame(best_results,columns=df_cols)\n",
    "best_results_df['Время подготовки модели (c)']=round(best_results_df['Время подготовки модели (c)'],2)\n",
    "best_results_df['Метрика валидации (F1)']=round(best_results_df['Метрика валидации (F1)'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>Время подготовки модели (c)</th>\n",
       "      <th>Метрика валидации (F1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>640.51</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression + BERT</td>\n",
       "      <td>607.22</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost + BERT</td>\n",
       "      <td>150.85</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Модель  Время подготовки модели (c)  \\\n",
       "0         Logistic Regression                       640.51   \n",
       "1                    CatBoost                          0.0   \n",
       "2                        LGBM                         0.18   \n",
       "3  Logistic Regression + BERT                       607.22   \n",
       "4             CatBoost + BERT                       150.85   \n",
       "5         Logistic Regression                          0.0   \n",
       "\n",
       "   Метрика валидации (F1)  \n",
       "0                    0.71  \n",
       "1                    0.71  \n",
       "2                    0.74  \n",
       "3                    0.93  \n",
       "4                    0.95  \n",
       "5                    0.66  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_stats =  best_results_df.loc[ best_results_df['Метрика валидации (F1)'] == best_results_df['Метрика валидации (F1)'].max() ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель заново, добавив к тестовым данным валидационные чтобы чуть улучшить качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_stats['Модель'].values[0] == 'Logistic Regression + BERT':\n",
    "    model_best_name = \"Logistic Regression + BERT\"\n",
    "    if BERT_ACTIVITY != 'results':\n",
    "        model_best      = model_log_regressor_bert    \n",
    "elif best_stats['Модель'].values[0] == 'CatBoost + BERT':\n",
    "    model_best_name = \"CatBoostClassifier + BERT\"\n",
    "    if BERT_ACTIVITY != 'results':\n",
    "        model_best      = model_catboost_bert  \n",
    "elif   best_stats['Модель'].values[0] == 'LGBM':\n",
    "    model_best      = model_lgbm\n",
    "    model_best_name = \"LGBMClassifier\"\n",
    "elif best_stats['Модель'].values[0] == 'CatBoost':\n",
    "    model_best      = model_catboost\n",
    "    model_best_name = \"CatBoostClassifier\"\n",
    "elif best_stats['Модель'].values[0] == 'Logistic Regression':\n",
    "    model_best      = model_log_regressor\n",
    "    model_best_name = \"Logistic Regression\"\n",
    "      \n",
    "else:\n",
    "    model_best_name = \"CatBoostClassifier\"\n",
    "    model_best      = model_catboost        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дообучим уже выбранную конечную модель, показавшую лучшую метрику (метрику при проверке на валидационной выборке), обучив её на выборке train+valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И проверим её одну уже на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pd.concat( [ data_train, data_valid ] ).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_best_name in ['LGBM','CatBoost','Logistic Regression']:\n",
    "    model_best.fit( data_final, data_final['toxic'] )\n",
    "    pred_test = model_best.predict(data_test)\n",
    "    f1_score_final = round(f1_score(data_test['toxic'],pred_test),2)\n",
    "else:\n",
    "    # Если расчеты BERT в данном блокноте не ведутся - \n",
    "    # грузим данные ранее произведенных расчетов\n",
    "    if BERT_ACTIVITY == 'results':\n",
    "        f1_catboost_bert_final = 0.95\n",
    "        f1_catboost_bert_valid = 0.95\n",
    "        f1_log_reg_bert_final = 0.94\n",
    "        f1_log_reg_bert_valid = 0.93\n",
    "        f1_score_final = 0.95\n",
    "    else:\n",
    "        model_best.fit( data_final, data_final['toxic'] )\n",
    "        pred_test = model_best.predict(data_test)\n",
    "        f1_score_final = round(f1_score(data_test['toxic'],pred_test),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmain: Лучшая модель: CatBoostClassifier + BERT\n",
      "gmain: Метрика на валидации: 0.95\n",
      "gmain: Метрика на тесте: 0.95\n"
     ]
    }
   ],
   "source": [
    "tprint(f'{host}: Лучшая модель: { model_best_name }')\n",
    "tprint(f'{host}: Метрика на валидации: { best_stats[\"Метрика валидации (F1)\"].values[0] }')\n",
    "tprint(f'{host}: Метрика на тесте: { f1_score_final }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование нейронной сети BERT дает существеннейший скачок в метрике, позволяющий с высокой точностью классифицировать токсичные комментарии.<BR>\n",
    "Модели без BERT также можно подтянуть к заданной по условию премлемой метрике 0.75, что можно сделать, добавив частотный анализ и возможно другие признаки.<BR>\n",
    "CatBoostClassifier при использовании BERT дает метрику на валидации 0.95 что говорит о хорошем балансе охвата и точности. <BR>\n",
    "Модель вполне можно ставить в продакшн."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprint(f\"{host}: ВЫПОЛНЕНИЕ СКРИПТА ЗАВЕРШЕНО\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
