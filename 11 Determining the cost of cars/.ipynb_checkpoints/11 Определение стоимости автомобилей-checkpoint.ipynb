{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение стоимости автомобилей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Версия: 1.0.0.1 <BR>\n",
    "<strong>Github:</strong> https://github.com/govermsk/chislennie_metodi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сервис по продаже автомобилей с пробегом «Не бит, не крашен» разрабатывает приложение для привлечения новых клиентов. В нём можно быстро узнать рыночную стоимость своего автомобиля. В вашем распоряжении исторические данные: технические характеристики, комплектации и цены автомобилей. Вам нужно построить модель для определения стоимости. \n",
    "\n",
    "Заказчику важны:\n",
    "\n",
    "- качество предсказания;\n",
    "- скорость предсказания;\n",
    "- время обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import platform\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from catboost import Pool, CatBoostRegressor, cv\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Использовать подгруженную таблицу: DOWNLOAD_PREPROCESSED_DATASET = True\n",
    "# Пересчитать данные с нуля: DOWNLOAD_PREPROCESSED_DATASET = False (займёт кучу времени)\n",
    "\n",
    "DOWNLOAD_PREPROCESSED_DATASET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт/установка прогресс-бара и LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгрузка библиотеки pandas_profiling для создания отчетов по таблицам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas_profiling ipywidgets tqdm lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбираем источник(и) для загрузки файлов данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = platform.node()\n",
    "filename = \"autos.csv\"\n",
    "\n",
    "# На машинах исполнителя проекта файл с данными доступен через символический путь, \n",
    "# ссылающийса на папку на яндекс.диске, где расположен загружаемый файл. \n",
    "# В случае если хостом где выполняется анализ является какая-либо другая машина, \n",
    "# используем путь по умолчанию.\n",
    "try:    \n",
    "    if host in ['22varivoda','Gover-pc','MSI']:\n",
    "        filepath    = 'C:/_YDsymlink/Python/datascience/Projects/20 - Численные методы/'\n",
    "    else:\n",
    "        filepath    = '/datasets/'\n",
    "except:\n",
    "    print(\"Не удалось подгрузить данные\")\n",
    "    \n",
    "pd.reset_option('^display.',silent=True)\n",
    "pd.set_option('display.float_format', str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_PREPROCESSED_DATASET == True:\n",
    "    # Подгрузка обработанной таблички\n",
    "    from io import BytesIO\n",
    "    import requests\n",
    "    spreadsheet_id_before_adequacy_check = '1XQJpZEWquYxrPrV_Z7YHHMbISpDgcmB3WxCto5MprMA'\n",
    "    before_adequacy_check_file_name = 'https://docs.google.com/spreadsheets/d/{}/export?format=csv'.format(spreadsheet_id_before_adequacy_check)\n",
    "\n",
    "df = pd.read_csv(filepath+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Первичный осмотр данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заполнение пропусков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим две функции, которые будут помогать нам искать значения для заполнения пустот."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая функция готовит табличку с объектами, сгруппированными по признакам по списку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors_table(df, equality_fields,target_field):\n",
    "    neighbors_table = df.groupby(equality_fields)[target_field].describe().reset_index()\n",
    "    return neighbors_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вторая функция ищет из этой таблички соседа для переданного объекта и смотрит нужное значение у него.\n",
    "Сосед подбирается сначала по одному совпадению признаков, потом по двум и так далее, пока не подберётся наиболее близкий сосед с таким количеством совпадающих признаков какое возможно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_popular(object, target_field, equality_fields, fill_table):\n",
    "\n",
    "    value = ''\n",
    "    all_eqs = np.full(fill_table.shape[0],True)\n",
    "    N = 1 \n",
    "\n",
    "    for ef in equality_fields:\n",
    "        eq = (fill_table[ef] == object[ef])\n",
    "\n",
    "        all_eqs = ((all_eqs) & (eq)) \n",
    "        filtered_table = fill_table.loc[(all_eqs)]\n",
    "        N+=1\n",
    "        v_count = filtered_table.shape[0]    \n",
    "        if v_count > 0:\n",
    "            if len(filtered_table.loc[filtered_table['top'].isna()==False]) > 0:\n",
    "                v = filtered_table.loc[filtered_table['top'].isna()==False,'top'].values[0]\n",
    "                if v != np.nan:\n",
    "                    value = v\n",
    "\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> удобные помощники\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FuelType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполняем пропуски поля, указывающего тип топлива с помощью ранее созданных функций, подбирающих значения по соседям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equality_fields = ['Brand','VehicleType','Model','Gearbox','Power','RegistrationYear']\n",
    "target_field = 'FuelType'\n",
    "\n",
    "if DOWNLOAD_PREPROCESSED_DATASET == False:\n",
    "    df_fuel_table = get_neighbors_table(df, equality_fields, target_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# выполняется примерно 9 минут\n",
    "if DOWNLOAD_PREPROCESSED_DATASET == False:\n",
    "    df.loc[~df['FuelType'].isin(['petrol','gasoline','lpg','cng','other','hybrid','electric']),target_field ] = df.loc[~df['FuelType'].isin(['petrol','gasoline','lpg','cng','other','hybrid','electric']) ].apply(get_popular,axis=1, args=(target_field,equality_fields,df_fuel_table,))\n",
    "    df.loc[df[target_field].isna(),target_field] = df.loc[df[target_field].isna()].apply(get_popular,axis=1, args=(target_field,equality_fields,df_fuel_table,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_PREPROCESSED_DATASET == False:\n",
    "    print(f\"Число пустых записей {target_field}: {len(df.loc[(df[target_field].isna())|(~df['FuelType'].isin(['petrol','gasoline','lpg','cng','other','hybrid','electric']))])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FuelType'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как не все поля заполнились по алгоритму наиболее подходящих значений - остальные пустоты заполним наиболее популярным значением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[~df[target_field].isin(['petrol','gasoline','lpg','cng','other','hybrid','electric']),target_field ] = df[target_field].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[~df['FuelType'].isin(['petrol','gasoline','lpg','cng','other','hybrid','electric']) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[df['FuelType'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### VehicleType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичным способом заполняем и столбец с типом кузова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equality_fields = ['Brand','Model','Gearbox','Power','FuelType','RegistrationYear']\n",
    "target_field = 'VehicleType'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[target_field].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_values_list = list(df[target_field].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if DOWNLOAD_PREPROCESSED_DATASET == False:\n",
    "    df_vehicle_type_table = get_neighbors_table(df, equality_fields, target_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if DOWNLOAD_PREPROCESSED_DATASET == False:\n",
    "    df.loc[(df[target_field].isna()) | (~df[target_field].isin(target_values_list)),target_field] = df.loc[(df[target_field].isna()) | (~df[target_field].isin(target_values_list))].apply(get_popular,axis=1, args=(target_field,equality_fields,df_vehicle_type_table,))\n",
    "#    df.loc[~df['VehicleType'].isin(target_values_list),target_field] = df.loc[~df['VehicleType'].isin(target_values_list)].apply(get_popular,axis=1, args=(target_field,equality_fields,df_vehicle_type_table,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_PREPROCESSED_DATASET == False:\n",
    "    print(f\"Число пустых записей {target_field}: {len(df.loc[(df[target_field].isna())|(~df[target_field].isin(target_values_list))])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как не все поля заполнились по алгоритму наиболее подходящих значений - остальные пустоты заполним наиболее популярным значением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[~df[target_field].isin(target_values_list),target_field ] = df[target_field].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_PREPROCESSED_DATASET == False:\n",
    "    print(f\"Число пустых записей {target_field}: {len(df.loc[(df[target_field].isna())|(~df[target_field].isin(target_values_list))])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gearbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_PREPROCESSED_DATASET == False:\n",
    "    equality_fields = ['Brand','Model','VehicleType','FuelType','Power','RegistrationYear']\n",
    "    target_field = 'Gearbox'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[target_field].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_values_list = list(df[target_field].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if DOWNLOAD_PREPROCESSED_DATASET == False:\n",
    "    df_gearbox_table = get_neighbors_table(df, equality_fields, target_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if DOWNLOAD_PREPROCESSED_DATASET == False:    \n",
    "    df.loc[(df[target_field].isna()) | (~df[target_field].isin(target_values_list)),target_field] = df.loc[(df[target_field].isna()) | (~df[target_field].isin(target_values_list))].apply(get_popular,axis=1, args=(target_field,equality_fields,df_gearbox_table,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если все же остались пустоты - заполним их \"ручной коробкой\" (наиболее популярным значением)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_PREPROCESSED_DATASET == False:\n",
    "    print(f\"Число пустых записей {target_field}: {len(df.loc[(df[target_field].isna())|(~df[target_field].isin(target_values_list))])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[~df[target_field].isin(target_values_list),target_field ] = df[target_field].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_PREPROCESSED_DATASET == False:\n",
    "    print(f\"Число пустых записей {target_field}: {len(df.loc[(df[target_field].isna())|(~df[target_field].isin(target_values_list))])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как восстановить модели всё равно не получится, указываем значение по-умолчанию (константу) = 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_PREPROCESSED_DATASET == False:\n",
    "    df.loc[df['Model'].isna(),'Model'] = 'unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repaired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае со столбцом <code>Repaired</code> будем исходить из соображений что скорее всего его заполняют в том случае если отметка о ремонте ставится. Значит при незаполненности этого столбца скорее всего должно быть указано значение no. Его и внесем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_PREPROCESSED_DATASET == False:    \n",
    "    target_field = 'Repaired'\n",
    "    target_values_list = list(df[target_field].value_counts().index)\n",
    "    \n",
    "    print(f\"Варианты поля Repaired:\\n{df['Repaired'].value_counts()}\")\n",
    "    \n",
    "    print(f\"\\nЧисло пустых записей {target_field}: {len(df.loc[(df[target_field].isna())|(~df[target_field].isin(target_values_list))])}\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_PREPROCESSED_DATASET == False:\n",
    "    df.loc[df['Repaired'].isna(),'Repaired'] = 'no'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого. Сверяемся со списком пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_PREPROCESSED_DATASET == False:\n",
    "    print(f'Пустых значений:\\n{df.isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропуски устранены. Займёмся анализом адекватности значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_PREPROCESSED_DATASET == True:\n",
    "    r_before_adequacy_check = requests.get(before_adequacy_check_file_name)\n",
    "    df = pd.read_csv(BytesIO(r_before_adequacy_check.content))\n",
    "    df = df.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка значений на адекватность, необходимость. Исправления значений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что будем проверять и исправлять:<BR>\n",
    "- <code>Price</code> - Цена. Если значений в этом столбце нет то такие объекты нам не нужны, так как они не помогут нам обучить модель. От таких объектов будем избавляться\n",
    "- <code>RegistrationYear</code> - стоит проверить на адекватность значений. Не было ли регистраций во времена Ноя, либо в будущем. Не было ли регистраций в даты, превышающие максимальную дату в столбце <code>DateCrawled</code>. Дата регистрации не может быть больше даты выгрузки данных. \n",
    "- <code>Power</code> - проверим на нереальные цифры. К примеру не может быть машины мощностью равной нулю либо 10 л/с, так же как и машины в несколько тысяч л/с. Попробуем поисправлять эти значения созданной ранее функцией\n",
    "- <code>Kilometer</code> - посмотрим, нет ли запредельных значений\n",
    "- <code>DateCreated</code> - проверим на реалистичность дат\n",
    "- <code>NumberOfPictures</code> - столбец не нужен, будем удалять\n",
    "- <code>PostalCode</code> -  столбец не нужен, будем удалять\n",
    "- <code>LastSeen</code> - тоже не нужный столбец"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Избавляемся от объектов для которых не указана цена, так как они бесполезны для обучения моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.loc[df['Price'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['Price'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим график цен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Price'].hist(bins=200,figsize=(8,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убираем записи с подозрительно дешевой ценой (<99 у.е.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['Price'] >= 99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RegistrationYear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если год регистрации больше года парсинга объявления - это ошибка. Исключим их из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = datetime.datetime.strptime(df['DateCrawled'].max(),'%Y-%m-%d %X')\n",
    "max_year = max_date.year\n",
    "max_year # Максимальный год парсинга объявлений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(df.loc[df['RegistrationYear'] > max_year])} - число объявлений с датой регистрации, превышающей максимальный год парсинга\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['RegistrationYear'] > max_year, 'RegistrationYear'] = max_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['RegistrationYear'] <= max_year]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим что с минимальными значениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['RegistrationYear'] < 1960]['RegistrationYear'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все понятно. Оставляем только значения от 1900 года (можно было бы взять скажем от 1950 и выше, но наверно неплохо бы оставить раритетные автомобили)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['RegistrationYear'] >= 1900]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как выглядит распределение по годам регистрации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RegistrationYear'].hist(bins=100,figsize=(8,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу посмотрим, что у нас по крайним значениям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Power'].value_counts().sort_index().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Power'].value_counts().sort_index().tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Восстановить данные о мощностях двигателей мы не можем, так что будем исключать те записи где указана неадекватная информация.<BR>\n",
    "Нижней границей адекватности будем считать мощность автомобиля-инвалидки - 18 л/с<BR>\n",
    "Чтобы понять верхнюю границу адекватности - посмотрим, есть ли в списке брендов те которые делают высокомощные суперкары.<BR>\n",
    "Если нет - ограничимся 800 л/с"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим в таблице автомобили с нулевой мощностью, предполагая что двигатель в них изьят, а записи где мощность 1-17 л/с уберём."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Brand'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В списке не видно ни Bugatti ни Aston Martin/Lotus/McLaren и т.п.<BR>\n",
    "Значит верхней границей поставим 800 л/с"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_min = 18\n",
    "power_max = 800\n",
    "df = df.loc[ ((df['Power'] >= power_min) & (df['Power'] <= power_max)) | (df['Power'] == 0 ) ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение мощностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Power'].hist(bins=100,figsize=(8,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kilometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Kilometer'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похоже что всё округлено и выбрасов нет. Едем дальше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DateCreated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateCreated'].value_counts().sort_index().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateCreated'].value_counts().sort_index().tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Претензий к значениям нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NumberOfPictures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Столбец не нужен, удаляем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='NumberOfPictures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PostalCode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Столбец не нужен, удаляем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='PostalCode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LastSeen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Столбец тоже не нужен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='LastSeen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DateCrawled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Столбец тоже не нужен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='DateCrawled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DateCreated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Столбец тоже не нужен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='DateCreated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repaired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем поле бинарным где 1 = ремонтировали, 0 - не ремонтировали"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Repaired']=='yes','Repaired'] = 1\n",
    "df.loc[df['Repaired']=='no','Repaired'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gearbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично полю Repaired сделаем поле бинарным, где 1 = автомат, 0 = ручная коробка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Gearbox']=='auto',  'Gearbox'] = 1\n",
    "df.loc[df['Gearbox']=='manual','Gearbox'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RegistrationMonth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С виду тоже не нужный столбец"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='RegistrationMonth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразование типов данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование памяти 25.7 мб"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price']             = pd.to_numeric( df['Price'], downcast='integer')\n",
    "df['Power']             = pd.to_numeric( df['Power'], downcast='integer')\n",
    "df['Kilometer']         = pd.to_numeric( df['Kilometer'], downcast='integer')\n",
    "df['RegistrationYear']  = pd.to_numeric( df['RegistrationYear'], downcast='integer')\n",
    "df['Gearbox']           = pd.to_numeric( df['Gearbox'],  downcast='integer')\n",
    "df['Repaired']          = pd.to_numeric( df['Repaired'], downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер таблички сделали чуть поменьше, 15.2 Мб"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод по предварительной обработке данных и их анализу:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ряд столбцов таблицы нам не потребовались: PostalCode, LastSeen, NumberOfPictures, DateCrawled, DateCreated, RegistrationMonth\n",
    "- Были выбросы в столбцах Power, RegistrationYear. Оставлены только те объекты, которые не относились к выбросам.\n",
    "- В значимых столбцах заполнены пропуски. В FuelType, VehicleType, GearBox значения подобраны по наиболее похожим для соответствующих объектов соседям.\n",
    "- В Model и Repaired пропуски заполнены константными значениями.\n",
    "- Из выборки исключены объекты где не указана цена.\n",
    "- Столбцы Gearbox, Repaired приведены к бинарному виду (значения у них теперь 1/0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим сколько получилось объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем модельки:\n",
    "- LinearRegression\n",
    "- Ridge\n",
    "- CatboostRegressor\n",
    "- LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим датасет results, в который будем сохранять показатели работы моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    ['LinearRegression','',0,0,0],\n",
    "    ['Ridge','',0,0,0],\n",
    "    ['CatboostRegressor','',0,0,0],\n",
    "    ['LGBMRegressor','',0,0,0]\n",
    "]\n",
    "results = pd.DataFrame(data,columns=['model','comment','learning_time','prediction_time','rmse_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для разнообразия воспользуемся Pipeline для подготовки данных для линейной регрессии. И для выбора столбцов сделаем небольшой класс ColumnSelector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Select only specified columns.\"\"\"\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для подготовки данных нужно сделать OHE-кодирование категориальных признаков и масштабирование числовых"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['Price']), \n",
    "                                                    df['Price'], \n",
    "                                                    test_size=.2, \n",
    "                                                    random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['VehicleType','Brand','Model','FuelType']\n",
    "numerical   = [c for c in df.columns if c not in categorical and c !='Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(categorical)),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('selector', ColumnSelector(numerical)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = FeatureUnion([\n",
    "    ('cat', cat_pipe),\n",
    "    ('num', num_pipe)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим также табличку где категориальные признаки кодированы через OrdinalEncoder без использования pipeline-Ов, назовем её df_ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "df_ordinal = df.copy()\n",
    "cat_features_ordinal = pd.DataFrame(\n",
    "                                      encoder.fit_transform( df[categorical] ),\n",
    "                                      columns=categorical,\n",
    "                                      index=df.index\n",
    "                       )\n",
    "\n",
    "for c in categorical:\n",
    "    df_ordinal[c] = cat_features_ordinal[c]\n",
    "df_ordinal.sample(3)\n",
    "\n",
    "X_train_ordinal, X_test_ordinal, y_train_ordinal, y_test_ordinal = train_test_split(df_ordinal.drop(columns=['Price']), \n",
    "                                                                                    df_ordinal['Price'], \n",
    "                                                                                    test_size=.2, \n",
    "                                                                                    random_state=RANDOM_STATE\n",
    "                                                                                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И табличку признаков где категориальные обработаны с применением OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_features = pd.get_dummies(df[categorical].copy(),drop_first=True)\n",
    "df_numerical = df[numerical].copy()\n",
    "df_price     = df['Price'].copy()\n",
    "\n",
    "df_ohe = pd.concat([df_numerical, ohe_features, df_price],axis=1)\n",
    "\n",
    "X_train_ohe, X_test_ohe, y_train_ohe, y_test_ohe = train_test_split(df_ohe.drop(columns=['Price']), \n",
    "                                                                                    df_ohe['Price'], \n",
    "                                                                                    test_size=.2, \n",
    "                                                                                    random_state=RANDOM_STATE\n",
    "                                                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для замера времени работы ячейки в jupyter notebook используется ключевое слово %%time. Но помимо него воспользуемся классом datetime для замера времени работы ячеек. Будем считать время в начале и в конце работы ячейки, а разницу сохранять в табличку results, которую создавали ранее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_linreg = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = (cross_val_score( pipe_linreg, \n",
    "                         X_train,\n",
    "                         y_train,\n",
    "                         cv = 5,\n",
    "                         scoring =\"neg_mean_squared_error\" ).mean() * -1) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "t_start = datetime.datetime.now()\n",
    "\n",
    "pipe_linreg.fit(X_train,y_train)\n",
    "\n",
    "t_end   = datetime.datetime.now()\n",
    "time_linear = t_end-t_start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_start = datetime.datetime.now()\n",
    "\n",
    "\n",
    "pipe_linreg.predict(X_train)\n",
    "\n",
    "tp_end   = datetime.datetime.now()\n",
    "time_linear_predict = tp_end-tp_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_linear = rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так себе результат. Не дотягивает до цифры которая нам нужна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[results['model'] == 'LinearRegression','learning_time'  ] = time_linear\n",
    "results.loc[results['model'] == 'LinearRegression','prediction_time'] = time_linear_predict\n",
    "results.loc[results['model'] == 'LinearRegression','rmse_score'     ] = rmse_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge (гребневая регрессия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # переменные\n",
    "    'alpha':[0.1,0.2,0.5,0.7],\n",
    "    'max_iter':[1000,1500,2000],\n",
    "    'solver':['svd','cholesky','sparse_cg','lsqr','sag'],\n",
    "    \n",
    "    # констатнтные \n",
    "    'copy_X':[True],\n",
    "    'fit_intercept':[False],\n",
    "    'random_state':[RANDOM_STATE]    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ridge = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rsearch_ridge = RandomizedSearchCV( model_ridge,\n",
    "                                    params ,\n",
    "                                    scoring='neg_mean_squared_error'\n",
    "                                  )\n",
    "\n",
    "rsearch_ridge.fit(X_train_ohe, y_train_ohe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_ridge = rsearch_ridge.best_params_\n",
    "best_params_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t_start = datetime.datetime.now()\n",
    "model_ridge = Ridge(\n",
    "                        alpha        = best_params_ridge['alpha'],\n",
    "                        max_iter     = best_params_ridge['max_iter'],\n",
    "                        solver       = best_params_ridge['solver'],\n",
    "                        copy_X       = best_params_ridge['copy_X'],\n",
    "                        random_state = best_params_ridge['random_state']\n",
    "                    )\n",
    "model_ridge.fit(X_train_ohe, y_train_ohe)\n",
    "\n",
    "t_end   = datetime.datetime.now()\n",
    "time_ridge = t_end - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_ridge = ((rsearch_ridge.best_score_) * -1) ** 0.5\n",
    "rmse_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тоже цифра неудачная, увы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замер времени предсказания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tp_start = datetime.datetime.now()\n",
    "\n",
    "model_ridge.predict(X_train_ohe)\n",
    "\n",
    "tp_end   = datetime.datetime.now()\n",
    "time_ridge_predict = tp_end-tp_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[results['model'] == 'Ridge','learning_time'  ] = time_ridge\n",
    "results.loc[results['model'] == 'Ridge','prediction_time'] = time_ridge_predict\n",
    "results.loc[results['model'] == 'Ridge','rmse_score'     ] = rmse_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пробуем считать catboost на GPU, а если система к этому не приспособлена - считаем на CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    params = [{ 'learning_rate':[0.1,0.3,0.5,0.6,0.7,0.8],\n",
    "                'iterations':[200,225,250,275,300],\n",
    "                'loss_function':['RMSE'],\n",
    "                'task_type':['GPU']\n",
    "              }]\n",
    "    c_boost = CatBoostRegressor(random_state=RANDOM_STATE,\n",
    "                                loss_function='RMSE',\n",
    "                                verbose=False)\n",
    "\n",
    "\n",
    "    rsearch_cat = RandomizedSearchCV( c_boost,\n",
    "                                      params \n",
    "                                    )\n",
    "    rsearch_cat.fit(X_train_ordinal, y_train_ordinal)\n",
    "\n",
    "    results.loc[results['model'] == 'CatboostRegressor','comment'  ] = 'GPU'\n",
    "    \n",
    "except:\n",
    "    params =  [{'learning_rate':[0.1,0.3,0.5,0.6,0.7,0.8],\n",
    "                'iterations':[200,225,250,275,300],\n",
    "                'loss_function':['RMSE'],\n",
    "                'task_type':['CPU']\n",
    "              }]\n",
    "    c_boost = CatBoostRegressor(random_state=RANDOM_STATE,\n",
    "                                loss_function='RMSE',\n",
    "                                verbose=False)\n",
    "\n",
    "    rsearch_cat = RandomizedSearchCV( c_boost,\n",
    "                                      params \n",
    "                                    )\n",
    "    rsearch_cat.fit(X_train_ordinal, y_train_ordinal)\n",
    "    \n",
    "    results.loc[results['model'] == 'CatboostRegressor','comment'  ] = 'CPU'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Замер времени обучения на подобранных параметрах\n",
    "c_boost = CatBoostRegressor(   \n",
    "                                learning_rate  = c_boost_best_params['learning_rate'],\n",
    "                                iterations     = c_boost_best_params['iterations'],\n",
    "                                loss_function  = c_boost_best_params['loss_function'],\n",
    "                                task_type      = c_boost_best_params['task_type'],\n",
    "                                verbose=False\n",
    "                            )\n",
    "t_start = datetime.datetime.now()\n",
    "\n",
    "c_boost.fit(X_train_ordinal, y_train_ordinal)    \n",
    "\n",
    "t_end   = datetime.datetime.now()  \n",
    "time_catboost = t_end-t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_boost_best_params = rsearch_cat.best_params_\n",
    "c_boost_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_boost_best_score = rsearch_cat.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замеряем время предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tp_start = datetime.datetime.now()\n",
    "\n",
    "y_pred_c_boost = rsearch_cat.predict(X_train_ordinal)\n",
    "\n",
    "tp_end   = datetime.datetime.now()\n",
    "time_catboost_predict = tp_end - tp_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_catboost = mean_squared_error(y_train_ordinal,y_pred_c_boost)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от линейной регрессии метрика регрессии стала удовлетворять требованиям задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[results['model'] == 'CatboostRegressor','learning_time'  ] = time_catboost\n",
    "results.loc[results['model'] == 'CatboostRegressor','prediction_time'] = time_catboost_predict\n",
    "results.loc[results['model'] == 'CatboostRegressor','rmse_score'     ] = rmse_catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_reg = LGBMRegressor(random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "           'boosting_type': ['gbdt'],\n",
    "           'num_leaves': [20,30,40,50,100,150,200],\n",
    "           'learning_rate': [0.1,0.2,0.3,0.4,0.5,0.6,0.7],\n",
    "           'n_estimators': [80,100,120,150]\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rsearch_lgbm = RandomizedSearchCV( lgb_reg,\n",
    "                                   params \n",
    "                                 )\n",
    "rsearch_lgbm.fit(X_train_ordinal, y_train_ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_best_params = rsearch_lgbm.best_params_\n",
    "lgbm_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_reg = LGBMRegressor(random_state = RANDOM_STATE,\n",
    "                        boosting_type = lgbm_best_params['boosting_type'],\n",
    "                        num_leaves = lgbm_best_params['num_leaves'],\n",
    "                        n_estimators = lgbm_best_params['n_estimators'],\n",
    "                        learning_rate = lgbm_best_params['learning_rate'],\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "t_start   = datetime.datetime.now()\n",
    "\n",
    "lgb_reg.fit(X_train_ordinal,y_train_ordinal)\n",
    "\n",
    "t_end     = datetime.datetime.now()\n",
    "time_lgbm = t_end-t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_start = datetime.datetime.now()\n",
    "\n",
    "y_pred_train_lgbm = lgb_reg.predict(X_train_ordinal)\n",
    "\n",
    "tp_end = datetime.datetime.now()\n",
    "time_lgbm_predict = tp_end - tp_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_lgbm = mean_squared_error(y_train_ordinal,y_pred_train_lgbm)**0.5\n",
    "rmse_lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хороший результат! Сохраняем в табличку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[results['model'] == 'LGBMRegressor','learning_time'  ] = time_lgbm\n",
    "results.loc[results['model'] == 'LGBMRegressor','prediction_time'] = time_lgbm_predict\n",
    "results.loc[results['model'] == 'LGBMRegressor','rmse_score'     ] = rmse_lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на цифры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Вывод</B>:<BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейные модели не тянут .... Учитывая выдаваемые ими значения метрики, время обучения и предсказания не интересны.<BR>\n",
    "Модели бустинга проявили себя хорошо, выдавая неплохие значения метрики. По скорости обучения выиграла LGBM, показав время обучения 1:23 против 2:22, несмотря на то что Catboost обучился на GPU. Метрика также лучше у LGBM. <BR>\n",
    "У Catboost преимущество оказалось по времени предсказания, но меньшее значение ошибки вё же поважнее<BR>\n",
    "При небольшом наборе гиперпараметров \"победителем\" становится LGBM-регрессия, засчет более низкой ошибки в предсказаниях (хотя сами предсказания и делаются чуть медленнее чем в catboost).<BR>Однако нужно учесть что если перебрать большее количество параметров, результат может измениться в пользу Catboost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем результат на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred_test_lgbm = lgb_reg.predict(X_test_ordinal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test_lgbm = mean_squared_error(y_test_ordinal,y_pred_test_lgbm)**0.5\n",
    "rmse_test_lgbm"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 18337,
    "start_time": "2022-12-26T21:36:32.360Z"
   },
   {
    "duration": 3,
    "start_time": "2022-12-26T21:45:20.475Z"
   },
   {
    "duration": 12,
    "start_time": "2022-12-26T21:45:20.481Z"
   },
   {
    "duration": 8,
    "start_time": "2022-12-26T21:45:20.495Z"
   },
   {
    "duration": 11,
    "start_time": "2022-12-26T21:45:20.504Z"
   },
   {
    "duration": 383,
    "start_time": "2022-12-26T21:47:50.303Z"
   },
   {
    "duration": 20,
    "start_time": "2022-12-26T21:48:02.422Z"
   },
   {
    "duration": 1147,
    "start_time": "2022-12-26T21:48:29.855Z"
   },
   {
    "duration": 25,
    "start_time": "2022-12-26T21:48:31.342Z"
   },
   {
    "duration": 92,
    "start_time": "2022-12-26T21:49:01.622Z"
   },
   {
    "duration": 143,
    "start_time": "2022-12-26T21:49:08.212Z"
   },
   {
    "duration": 21,
    "start_time": "2022-12-26T21:49:15.211Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-10T13:34:03.417Z"
   },
   {
    "duration": 5848,
    "start_time": "2023-01-10T13:34:03.433Z"
   },
   {
    "duration": 672,
    "start_time": "2023-01-10T13:34:09.283Z"
   },
   {
    "duration": 90,
    "start_time": "2023-01-10T13:34:09.957Z"
   },
   {
    "duration": 16187,
    "start_time": "2023-01-10T13:34:10.049Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-10T13:34:26.238Z"
   },
   {
    "duration": 28,
    "start_time": "2023-01-10T13:34:26.243Z"
   },
   {
    "duration": 3019,
    "start_time": "2023-01-10T13:34:26.273Z"
   },
   {
    "duration": 22,
    "start_time": "2023-01-10T13:34:29.294Z"
   },
   {
    "duration": 102,
    "start_time": "2023-01-10T13:34:29.318Z"
   },
   {
    "duration": 82,
    "start_time": "2023-01-10T13:34:29.422Z"
   },
   {
    "duration": 103,
    "start_time": "2023-01-10T13:34:29.505Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-10T13:34:29.609Z"
   },
   {
    "duration": 19,
    "start_time": "2023-01-10T13:34:29.618Z"
   },
   {
    "duration": 65513,
    "start_time": "2023-01-10T13:34:29.639Z"
   },
   {
    "duration": 221944,
    "start_time": "2023-01-10T13:35:35.154Z"
   },
   {
    "duration": 35,
    "start_time": "2023-01-10T13:39:17.099Z"
   },
   {
    "duration": 26,
    "start_time": "2023-01-10T13:39:17.136Z"
   },
   {
    "duration": 43,
    "start_time": "2023-01-10T13:39:17.164Z"
   },
   {
    "duration": 20,
    "start_time": "2023-01-10T13:39:17.208Z"
   },
   {
    "duration": 15,
    "start_time": "2023-01-10T13:39:17.230Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-10T13:39:17.246Z"
   },
   {
    "duration": 29,
    "start_time": "2023-01-10T13:39:17.257Z"
   },
   {
    "duration": 25,
    "start_time": "2023-01-10T13:39:17.288Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-10T13:40:13.883Z"
   },
   {
    "duration": 2882,
    "start_time": "2023-01-10T13:40:16.764Z"
   },
   {
    "duration": 703,
    "start_time": "2023-01-10T13:40:19.648Z"
   },
   {
    "duration": 110,
    "start_time": "2023-01-10T13:40:20.353Z"
   },
   {
    "duration": 743,
    "start_time": "2023-01-10T13:40:20.465Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-10T13:40:21.209Z"
   },
   {
    "duration": 12,
    "start_time": "2023-01-10T13:40:21.214Z"
   },
   {
    "duration": 814,
    "start_time": "2023-01-10T13:40:21.228Z"
   },
   {
    "duration": 25,
    "start_time": "2023-01-10T13:40:22.044Z"
   },
   {
    "duration": 112,
    "start_time": "2023-01-10T13:40:22.071Z"
   },
   {
    "duration": 92,
    "start_time": "2023-01-10T13:40:22.185Z"
   },
   {
    "duration": 99,
    "start_time": "2023-01-10T13:40:22.279Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-10T13:40:22.380Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-10T13:40:22.385Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-10T13:40:22.399Z"
   },
   {
    "duration": 18,
    "start_time": "2023-01-10T13:40:22.414Z"
   },
   {
    "duration": 23,
    "start_time": "2023-01-10T13:40:22.434Z"
   },
   {
    "duration": 43,
    "start_time": "2023-01-10T13:40:22.458Z"
   },
   {
    "duration": 48,
    "start_time": "2023-01-10T13:40:22.503Z"
   },
   {
    "duration": 25,
    "start_time": "2023-01-10T13:40:22.553Z"
   },
   {
    "duration": 32,
    "start_time": "2023-01-10T13:40:22.579Z"
   },
   {
    "duration": 14,
    "start_time": "2023-01-10T13:40:22.613Z"
   },
   {
    "duration": 38,
    "start_time": "2023-01-10T13:40:22.628Z"
   },
   {
    "duration": 27,
    "start_time": "2023-01-10T13:40:22.667Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-10T13:40:22.695Z"
   },
   {
    "duration": 15,
    "start_time": "2023-01-10T13:40:22.704Z"
   },
   {
    "duration": 20,
    "start_time": "2023-01-10T13:40:22.721Z"
   },
   {
    "duration": 45,
    "start_time": "2023-01-10T13:40:22.742Z"
   },
   {
    "duration": 14,
    "start_time": "2023-01-10T13:40:22.791Z"
   },
   {
    "duration": 14,
    "start_time": "2023-01-10T13:40:22.807Z"
   },
   {
    "duration": 40,
    "start_time": "2023-01-10T13:40:22.822Z"
   },
   {
    "duration": 33,
    "start_time": "2023-01-10T13:40:22.863Z"
   },
   {
    "duration": 11,
    "start_time": "2023-01-10T13:40:22.898Z"
   },
   {
    "duration": 18,
    "start_time": "2023-01-10T13:40:22.910Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-10T13:40:22.930Z"
   },
   {
    "duration": 46,
    "start_time": "2023-01-10T13:40:22.944Z"
   },
   {
    "duration": 2,
    "start_time": "2023-01-10T13:40:22.992Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-10T13:40:22.996Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-10T13:40:23.010Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-10T13:40:23.019Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-10T13:40:23.028Z"
   },
   {
    "duration": 23712,
    "start_time": "2023-01-10T13:40:23.037Z"
   },
   {
    "duration": 15,
    "start_time": "2023-01-10T13:40:46.750Z"
   },
   {
    "duration": 65,
    "start_time": "2023-01-10T13:40:46.766Z"
   },
   {
    "duration": 470,
    "start_time": "2023-01-10T13:40:46.835Z"
   },
   {
    "duration": 47,
    "start_time": "2023-01-10T13:40:47.307Z"
   },
   {
    "duration": 21,
    "start_time": "2023-01-10T13:40:47.356Z"
   },
   {
    "duration": 12,
    "start_time": "2023-01-10T13:40:47.379Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-10T13:40:47.393Z"
   },
   {
    "duration": 62,
    "start_time": "2023-01-10T13:40:47.399Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-10T13:40:47.462Z"
   },
   {
    "duration": 39,
    "start_time": "2023-01-10T13:40:47.471Z"
   },
   {
    "duration": 254,
    "start_time": "2023-01-10T13:40:47.512Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-10T13:40:47.768Z"
   },
   {
    "duration": 12,
    "start_time": "2023-01-10T13:40:47.776Z"
   },
   {
    "duration": 22,
    "start_time": "2023-01-10T13:40:47.789Z"
   },
   {
    "duration": 43,
    "start_time": "2023-01-10T13:40:47.826Z"
   },
   {
    "duration": 252,
    "start_time": "2023-01-10T13:40:47.871Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-10T13:40:48.124Z"
   },
   {
    "duration": 54,
    "start_time": "2023-01-10T13:40:48.132Z"
   },
   {
    "duration": 39,
    "start_time": "2023-01-10T13:40:48.187Z"
   },
   {
    "duration": 59,
    "start_time": "2023-01-10T13:40:48.227Z"
   },
   {
    "duration": 34,
    "start_time": "2023-01-10T13:40:48.287Z"
   },
   {
    "duration": 31,
    "start_time": "2023-01-10T13:40:48.323Z"
   },
   {
    "duration": 25,
    "start_time": "2023-01-10T13:40:48.356Z"
   },
   {
    "duration": 20,
    "start_time": "2023-01-10T13:40:48.383Z"
   },
   {
    "duration": 58,
    "start_time": "2023-01-10T13:40:48.405Z"
   },
   {
    "duration": 41,
    "start_time": "2023-01-10T13:40:48.465Z"
   },
   {
    "duration": 29,
    "start_time": "2023-01-10T13:40:48.508Z"
   },
   {
    "duration": 78,
    "start_time": "2023-01-10T13:40:48.539Z"
   },
   {
    "duration": 87,
    "start_time": "2023-01-10T13:40:48.618Z"
   },
   {
    "duration": 48,
    "start_time": "2023-01-10T13:40:48.706Z"
   },
   {
    "duration": 24,
    "start_time": "2023-01-10T13:40:48.756Z"
   },
   {
    "duration": 17,
    "start_time": "2023-01-10T13:40:48.782Z"
   },
   {
    "duration": 20,
    "start_time": "2023-01-10T13:40:48.801Z"
   },
   {
    "duration": 66,
    "start_time": "2023-01-10T13:40:48.822Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-10T13:40:48.889Z"
   },
   {
    "duration": 12,
    "start_time": "2023-01-10T13:40:48.893Z"
   },
   {
    "duration": 354,
    "start_time": "2023-01-10T13:40:48.907Z"
   },
   {
    "duration": 1256,
    "start_time": "2023-01-10T13:40:49.263Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-10T13:40:50.520Z"
   },
   {
    "duration": 19,
    "start_time": "2023-01-10T13:40:50.527Z"
   },
   {
    "duration": 98589,
    "start_time": "2023-01-10T13:40:50.547Z"
   },
   {
    "duration": 24499,
    "start_time": "2023-01-10T13:42:29.227Z"
   },
   {
    "duration": 98904,
    "start_time": "2023-01-10T13:42:53.731Z"
   },
   {
    "duration": 94,
    "start_time": "2023-01-10T13:44:32.637Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
